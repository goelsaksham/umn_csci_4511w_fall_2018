<!DOCTYPE html>
<!-- saved from url=(0052)https://en.wikipedia.org/wiki/Long_short-term_memory -->
<html class="client-js gr__en_wikipedia_org ve-not-available" lang="en" dir="ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Long short-term memory - Wikipedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Long_short-term_memory","wgTitle":"Long short-term memory","wgCurRevisionId":870076484,"wgRevisionId":870076484,"wgArticleId":10711453,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["All articles with unsourced statements","Articles with unsourced statements from October 2017","All articles with specifically marked weasel-worded phrases","Articles with specifically marked weasel-worded phrases from November 2017","Wikipedia articles needing clarification from October 2017","Artificial neural networks"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Long_short-term_memory","wgRelevantArticleId":10711453,"wgRequestId":"XAjj4gpAAEYAAHOA4BIAAACA","wgCSPNonce":false,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikiEditorEnabledModules":[],"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsShouldSendModuleToUser":true,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en","usePageImages":true,"usePageDescriptions":true},"wgMFExpandAllSectionsUserOption":true,"wgMFEnableFontChanger":true,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgWMESchemaEditAttemptStepOversample":false,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgWikibaseItemId":"Q6673524","wgScoreNoteLanguages":{"arabic":"العربية","catalan":"català","deutsch":"Deutsch","english":"English","espanol":"español","italiano":"italiano","nederlands":"Nederlands","norsk":"norsk","portugues":"português","suomi":"suomi","svenska":"svenska","vlaams":"West-Vlams"},"wgScoreDefaultNoteLanguage":"nederlands","wgCentralAuthMobileDomain":false,"wgCodeMirrorEnabled":true,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":true});mw.loader.state({"ext.gadget.charinsert-styles":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"});mw.loader.implement("user.tokens@0tffind",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.user","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging.subscriber","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.compactlinks","ext.uls.interface","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];mw.loader.load(RLPAGEMODULES);});</script>
<link rel="stylesheet" href="./Long short-term memory - Wikipedia_files/load.php">
<script async="" src="./Long short-term memory - Wikipedia_files/load(1).php"></script>
<style>
.mw-editfont-monospace{font-family:monospace,monospace}.mw-editfont-sans-serif{font-family:sans-serif}.mw-editfont-serif{font-family:serif} .mw-editfont-monospace,.mw-editfont-sans-serif,.mw-editfont-serif{font-size:13px; }.mw-editfont-monospace.oo-ui-textInputWidget,.mw-editfont-sans-serif.oo-ui-textInputWidget,.mw-editfont-serif.oo-ui-textInputWidget{font-size:inherit}.mw-editfont-monospace > .oo-ui-inputWidget-input,.mw-editfont-sans-serif > .oo-ui-inputWidget-input,.mw-editfont-serif > .oo-ui-inputWidget-input{font-size:13px}
.mw-ui-button{background-color:#f8f9fa;color:#222222;display:inline-block;-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;min-width:4em;max-width:28.75em;margin:0;padding:0.546875em 1em;border:1px solid #a2a9b1;border-radius:2px;font-family:inherit;font-size:1em;font-weight:bold;line-height:1.286;text-align:center;-webkit-appearance:none;*display:inline; zoom:1;vertical-align:middle;cursor:pointer}.mw-ui-button:visited{color:#222222}.mw-ui-button:hover{background-color:#ffffff;color:#444444;border-color:#a2a9b1}.mw-ui-button:focus{background-color:#ffffff;color:#222222;border-color:#3366cc;box-shadow:inset 0 0 0 1px #3366cc,inset 0 0 0 2px #ffffff;outline-width:0}.mw-ui-button:focus::-moz-focus-inner{border-color:transparent;padding:0}.mw-ui-button:active,.mw-ui-button.is-on{background-color:#c8ccd1;color:#000000;border-color:#72777d;box-shadow:none}.mw-ui-button:disabled,.mw-ui-button.mw-ui-quiet.mw-ui-progressive,.mw-ui-button.mw-ui-quiet.mw-ui-destructive{background-color:#c8ccd1;color:#ffffff;border-color:#c8ccd1;cursor:default}.mw-ui-button:disabled:hover,.mw-ui-button.mw-ui-quiet.mw-ui-progressive:hover,.mw-ui-button.mw-ui-quiet.mw-ui-destructive:hover,.mw-ui-button:disabled:active,.mw-ui-button.mw-ui-quiet.mw-ui-progressive:active,.mw-ui-button.mw-ui-quiet.mw-ui-destructive:active{background-color:#c8ccd1;color:#ffffff;box-shadow:none;border-color:#c8ccd1}.mw-ui-button:not(:disabled){-webkit-transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms;-moz-transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms;transition:background-color 100ms,color 100ms,border-color 100ms,box-shadow 100ms}.mw-ui-button.mw-ui-quiet{background-color:transparent;color:#222222;border-color:transparent}.mw-ui-button.mw-ui-quiet:hover{background-color:transparent;color:#444444;border-color:transparent;box-shadow:none}.mw-ui-button.mw-ui-quiet:active{background-color:transparent;color:#000000;border-color:transparent}.mw-ui-button.mw-ui-quiet:focus{background-color:transparent;color:#222222;border-color:transparent;box-shadow:none}.mw-ui-button.mw-ui-quiet:disabled{background-color:transparent;color:#c8ccd1;border-color:transparent}.mw-ui-button.mw-ui-progressive{background-color:#3366cc;color:#fff;border:1px solid #3366cc}.mw-ui-button.mw-ui-progressive:hover{background-color:#447ff5;border-color:#447ff5}.mw-ui-button.mw-ui-progressive:focus{box-shadow:inset 0 0 0 1px #3366cc,inset 0 0 0 2px #ffffff}.mw-ui-button.mw-ui-progressive:active,.mw-ui-button.mw-ui-progressive.is-on{background-color:#2a4b8d;border-color:#2a4b8d;box-shadow:none}.mw-ui-button.mw-ui-progressive:disabled{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1}.mw-ui-button.mw-ui-progressive:disabled:hover,.mw-ui-button.mw-ui-progressive:disabled:active{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1;box-shadow:none}.mw-ui-button.mw-ui-progressive.mw-ui-quiet{color:#3366cc}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:hover{background-color:transparent;color:#447ff5}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:active{color:#2a4b8d}.mw-ui-button.mw-ui-progressive.mw-ui-quiet:focus{background-color:transparent;color:#3366cc}.mw-ui-button.mw-ui-destructive{background-color:#dd3333;color:#fff;border:1px solid #dd3333}.mw-ui-button.mw-ui-destructive:hover{background-color:#ff4242;border-color:#ff4242}.mw-ui-button.mw-ui-destructive:focus{box-shadow:inset 0 0 0 1px #dd3333,inset 0 0 0 2px #ffffff}.mw-ui-button.mw-ui-destructive:active,.mw-ui-button.mw-ui-destructive.is-on{background-color:#b32424;border-color:#b32424;box-shadow:none}.mw-ui-button.mw-ui-destructive:disabled{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1}.mw-ui-button.mw-ui-destructive:disabled:hover,.mw-ui-button.mw-ui-destructive:disabled:active{background-color:#c8ccd1;color:#fff;border-color:#c8ccd1;box-shadow:none}.mw-ui-button.mw-ui-destructive.mw-ui-quiet{color:#dd3333}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:hover{background-color:transparent;color:#ff4242}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:active{color:#b32424}.mw-ui-button.mw-ui-destructive.mw-ui-quiet:focus{background-color:transparent;color:#dd3333}.mw-ui-button.mw-ui-big{font-size:1.3em}.mw-ui-button.mw-ui-block{display:block;width:100%;margin-left:auto;margin-right:auto}input.mw-ui-button::-moz-focus-inner,button.mw-ui-button::-moz-focus-inner{margin-top:-1px;margin-bottom:-1px}a.mw-ui-button{text-decoration:none}a.mw-ui-button:hover,a.mw-ui-button:focus{text-decoration:none}.mw-ui-button-group > *{min-width:48px;border-radius:0;float:left}.mw-ui-button-group > *:first-child{border-top-left-radius:2px;border-bottom-left-radius:2px}.mw-ui-button-group > *:not(:first-child){border-left:0}.mw-ui-button-group > *:last-child{border-top-right-radius:2px;border-bottom-right-radius:2px}.mw-ui-button-group .is-on .button{cursor:default}
.mw-ui-icon{position:relative;line-height:1.5em;min-height:1.5em;min-width:1.5em}span.mw-ui-icon{display:inline-block}.mw-ui-icon.mw-ui-icon-element{text-indent:-999px;overflow:hidden;width:3.5em;min-width:3.5em;max-width:3.5em}.mw-ui-icon.mw-ui-icon-element:before{left:0;right:0;position:absolute;margin:0 1em}.mw-ui-icon.mw-ui-icon-element.mw-ui-icon-large{width:4.625em;min-width:4.625em;max-width:4.625em;line-height:4.625em;min-height:4.625em}.mw-ui-icon.mw-ui-icon-element.mw-ui-icon-large:before{min-height:4.625em}.mw-ui-icon.mw-ui-icon-before:before,.mw-ui-icon.mw-ui-icon-element:before{background-position:50% 50%;background-repeat:no-repeat;background-size:100% auto;float:left;display:block;min-height:1.5em;content:''}.mw-ui-icon.mw-ui-icon-before:before{position:relative;width:1.5em;margin-right:1em}.mw-ui-icon.mw-ui-icon-small:before{background-size:66.67% auto}
.cite-accessibility-label{ top:-99999px;clip:rect(1px 1px 1px 1px); clip:rect(1px,1px,1px,1px); position:absolute !important;padding:0 !important;border:0 !important;height:1px !important;width:1px !important; overflow:hidden}:target .mw-cite-targeted-backlink{font-weight:bold}.mw-cite-up-arrow-backlink{display:none}:target .mw-cite-up-arrow-backlink{display:inline}:target .mw-cite-up-arrow{display:none}
.wp-teahouse-question-form{position:absolute;margin-left:auto;margin-right:auto;background-color:#f4f3f0;border:1px solid #a7d7f9;padding:1em}#wp-th-question-ask{float:right}.wp-teahouse-ask a.external{background-image:none !important}.wp-teahouse-respond-form{position:absolute;margin-left:auto;margin-right:auto;background-color:#f4f3f0;border:1px solid #a7d7f9;padding:1em}.wp-th-respond{float:right}.wp-teahouse-respond a.external{background-image:none !important}
.referencetooltip{position:absolute;list-style:none;list-style-image:none;opacity:0;font-size:12px;margin:0;z-index:5;padding:0}.referencetooltip > li{background:#fff;border:1px solid #bbb;-webkit-box-shadow:0 0 10px rgba(0,0,0,0.2);-moz-box-shadow:0 0 10px rgba(0,0,0,0.2);box-shadow:0 0 10px rgba(0,0,0,0.2);margin:0;padding:8px 10px;line-height:18px;max-width:300px}.referencetooltip > li + li{box-sizing:border-box;margin-left:7px;margin-top:-1px;border:0;padding:0;height:3px;width:0;background-color:transparent;-webkit-box-shadow:none;-moz-box-shadow:none;box-shadow:none;border-top:12px #bbb solid;border-right:7px transparent solid;border-left:7px transparent solid}.referencetooltip > li + li::after{z-index:111;content:'';border:6px solid transparent;border-bottom:0;border-top:8px solid #fff;height:0;width:0;display:block;margin-left:-6px;margin-top:-12px}.RTflipped{padding-top:13px}.referencetooltip.RTflipped > li + li{position:absolute;top:0;border-top:0;border-bottom:12px #bbb solid}.referencetooltip.RTflipped > li + li::after{border-top:0;border-bottom:8px #fff solid;position:absolute;margin-top:7px}.RTsettings{ background-image:linear-gradient(transparent,transparent),url(data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%3F%3E%0D%0A%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%2024%2024%22%3E%0D%0A%20%20%20%20%3Cpath%20fill%3D%22%23555%22%20d%3D%22M20%2014.5v-2.9l-1.8-.3c-.1-.4-.3-.8-.6-1.4l1.1-1.5-2.1-2.1-1.5%201.1c-.5-.3-1-.5-1.4-.6L13.5%205h-2.9l-.3%201.8c-.5.1-.9.3-1.4.6L7.4%206.3%205.3%208.4l1%201.5c-.3.5-.4.9-.6%201.4l-1.7.2v2.9l1.8.3c.1.5.3.9.6%201.4l-1%201.5%202.1%202.1%201.5-1c.4.2.9.4%201.4.6l.3%201.8h3l.3-1.8c.5-.1.9-.3%201.4-.6l1.5%201.1%202.1-2.1-1.1-1.5c.3-.5.5-1%20.6-1.4l1.5-.3zM12%2016c-1.7%200-3-1.3-3-3s1.3-3%203-3%203%201.3%203%203-1.3%203-3%203z%22%2F%3E%0D%0A%3C%2Fsvg%3E);  display:block;float:right;cursor:pointer;margin:0;margin-top:-4px;height:24px;width:24px;border-radius:2px;box-sizing:border-box;background-position:center center;background-repeat:no-repeat;background-size:24px 24px;margin-left:8px}.RTsettings:hover{background-color:#eee}.RTTarget{background-color:#def}
.suggestions{overflow:hidden;position:absolute;top:0;left:0;width:0;border:0;z-index:1099;padding:0;margin:-1px 0 0 0}.suggestions-special{position:relative;background-color:#fff;cursor:pointer;border:1px solid #a2a9b1;margin:0;margin-top:-2px;display:none;padding:0.25em 0.25em;line-height:1.25em}.suggestions-results{background-color:#fff;cursor:pointer;border:1px solid #a2a9b1;padding:0;margin:0}.suggestions-result{color:#000;margin:0;line-height:1.5em;padding:0.01em 0.25em;text-align:left; overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.suggestions-result-current{background-color:#2a4b8d;color:#fff}.suggestions-special .special-label{color:#72777d;text-align:left}.suggestions-special .special-query{color:#000;font-style:italic;text-align:left}.suggestions-special .special-hover{background-color:#c8ccd1}.suggestions-result-current .special-label,.suggestions-result-current .special-query{color:#fff}.highlight{font-weight:bold}
@media screen {
	.tochidden,.toctoggle{-moz-user-select:none;-webkit-user-select:none;-ms-user-select:none;user-select:none}.toctoggle{font-size:94%}}
@media print {
	.toc.tochidden,.toctoggle{display:none}}
@-webkit-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-webkit-transform:translateY(-20px)}100%{opacity:1;-webkit-transform:translateY(0)}}@-moz-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-moz-transform:translateY(-20px)}100%{opacity:1;-moz-transform:translateY(0)}}@-o-keyframes centralAuthPPersonalAnimation{0%{opacity:0;-o-transform:translateY(-20px)}100%{opacity:1;-o-transform:translateY(0)}}@keyframes centralAuthPPersonalAnimation{0%{opacity:0;transform:translateY(-20px)}100%{opacity:1;transform:translateY(0)}}.centralAuthPPersonalAnimation{-webkit-animation-duration:1s;-moz-animation-duration:1s;-o-animation-duration:1s;animation-duration:1s;-webkit-animation-fill-mode:both;-moz-animation-fill-mode:both;-o-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-name:centralAuthPPersonalAnimation;-moz-animation-name:centralAuthPPersonalAnimation;-o-animation-name:centralAuthPPersonalAnimation;animation-name:centralAuthPPersonalAnimation}
@media print{#centralNotice{display:none}}.cn-closeButton{display:inline-block;zoom:1;background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUBAMAAAB/pwA+AAAAElBMVEUAAAAQEBDPz88AAABAQEDv7+9oe1vvAAAABnRSTlMA3rLe3rJS22KzAAAARElEQVQI12PAAUIUQCSTK5BwFgIxFU1AhKECUFAYKAAioXwwBeZChMGCEGGQIFQYJohgIhQgtCEMQ7ECYTHCOciOxA4AADgJTXIb9s8AAAAASUVORK5CYII=) no-repeat;background:url(/w/extensions/CentralNotice/resources/subscribing/close.png?8e3d8) no-repeat!ie;width:20px;height:20px;text-indent:20px;white-space:nowrap;overflow:hidden}
.uls-menu{border-radius:2px; font-size:medium}.uls-search,.uls-language-settings-close-block{border-top-right-radius:2px;border-top-left-radius:2px}.uls-language-list{border-bottom-right-radius:2px;border-bottom-left-radius:2px}.uls-menu.callout:before,.uls-menu.callout:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.uls-menu.callout.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.uls-menu.callout.selector-right:after{ border-left:10px solid #fff; right:-10px}.uls-menu.callout.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.uls-menu.callout.selector-left:after{ border-right:10px solid #fff; left:-10px}.uls-ui-languages button{margin:5px 15px 5px 0;white-space:nowrap;overflow:hidden}.uls-search-wrapper-wrapper{position:relative;padding-left:40px;margin-top:5px;margin-bottom:5px}.uls-icon-back{background:transparent url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.png?90e9b) no-repeat scroll center center;background-image:-webkit-linear-gradient(transparent,transparent),url(/w/extensions/UniversalLanguageSelector/resources/images/back-grey-ltr.svg?e226b);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2224%22 height=%2224%22 viewBox=%220 0 24 24%22%3E %3Cpath fill=%22%2354595d%22 d=%22M7 13.1l8.9 8.9c.8-.8.8-2 0-2.8l-6.1-6.1 6-6.1c.8-.8.8-2 0-2.8L7 13.1z%22/%3E %3C/svg%3E");background-size:28px;background-position:center center;height:32px;width:40px;display:block;position:absolute;left:0;border-right:1px solid #c8ccd1;opacity:0.8}.uls-icon-back:hover{opacity:1;cursor:pointer}.uls-menu .uls-no-results-view .uls-no-found-more{background-color:#fff}.uls-menu .uls-no-results-view h3{padding:0 28px;margin:0;color:#54595d;font-size:1em;font-weight:normal}  .skin-vector .uls-menu{border-color:#c8ccd1;-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);font-size:0.875em}.skin-vector .uls-search{border-bottom-color:#c8ccd1}.skin-vector .uls-filtersuggestion{color:#72777d}.skin-vector .uls-lcd-region-title{color:#54595d}
.mw-ui-icon-popups-settings:before{background-image:url(/w/load.php?modules=ext.popups.images&image=popups-settings&format=rasterized&lang=en&skin=vector&version=0mti6id);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Cg fill=%22%2354595d%22%3E %3Cpath d=%22M10.112 4.554a5.334 5.334 0 1 0 0 10.668 5.334 5.334 0 0 0 0-10.668zm0 7.823a2.49 2.49 0 1 1 0-4.978 2.49 2.49 0 0 1 0 4.978z%22/%3E %3Cpath d=%22M11.4 5.303L11.05 3h-2.1L8.6 5.303a4.9 4.9 0 0 1 2.8 0zm-2.8 9.394L8.95 17h2.1l.35-2.303a4.9 4.9 0 0 1-2.8 0zm5.712-7.028l1.4-1.876L14.2 4.309l-1.876 1.4a4.9 4.9 0 0 1 1.981 1.981l.007-.021zm-8.624 4.662L4.309 14.2 5.8 15.691l1.876-1.4a4.9 4.9 0 0 1-1.981-1.981l-.007.021zm9.009-.931L17 11.05v-2.1l-2.303-.35a4.9 4.9 0 0 1 0 2.8zM5.303 8.6L3 8.95v2.1l2.303.35a4.9 4.9 0 0 1 0-2.8zm7.028 5.712l1.876 1.4 1.484-1.512-1.4-1.876a4.9 4.9 0 0 1-1.981 1.981l.021.007zM7.669 5.688L5.8 4.309 4.309 5.8l1.4 1.876a4.9 4.9 0 0 1 1.96-1.988z%22/%3E %3C/g%3E %3C/svg%3E")}.mw-ui-icon-popups-close:before{background-image:url(/w/load.php?modules=ext.popups.images&image=popups-close&format=rasterized&lang=en&skin=vector&version=0mti6id);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Cpath d=%22M3.636 2.222l14.142 14.142-1.414 1.414L2.222 3.636z%22/%3E %3Cpath d=%22M17.778 3.636L3.636 17.778l-1.414-1.414L16.364 2.222z%22/%3E %3C/svg%3E")}.mw-ui-icon-preview-generic:before{background-image:url(/w/load.php?modules=ext.popups.images&image=preview-generic&format=rasterized&lang=en&skin=vector&version=0mti6id);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2237%22 height=%2227%22 viewBox=%220 0 37 27%22%3E %3Cg fill=%22%23c8ccd1%22 fill-rule=%22evenodd%22%3E %3Cpath d=%22M5.475.7v20.075L0 26.25h31.025c3.102 0 5.475-2.372 5.475-5.475V.7H5.475zm20.44 4.562c1.277 0 2.19 1.095 2.19 2.19 0 1.096-.913 2.373-2.19 2.373-1.278 0-2.19-1.095-2.19-2.19s1.095-2.373 2.19-2.373zm-9.855 0c1.277 0 2.19 1.095 2.19 2.19 0 1.096-1.095 2.373-2.19 2.373s-2.19-1.095-2.19-2.19.913-2.373 2.19-2.373zm4.928 8.213c-7.153 0-8.415 7.012-8.415 7.012s2.805-1.403 8.415-1.403c5.61 0 8.414 1.403 8.414 1.403S28 13.475 20.988 13.475z%22/%3E %3C/g%3E %3C/svg%3E")}.mw-ui-icon-footer:before{background-image:url(/w/load.php?modules=ext.popups.images&image=footer&format=rasterized&lang=en&skin=vector&version=0mti6id);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 xmlns:xlink=%22http://www.w3.org/1999/xlink%22 width=%22230%22 height=%22179%22 viewBox=%220 0 230 179%22%3E %3Cdefs%3E %3Crect id=%22a%22 width=%22201%22 height=%2213%22 rx=%222%22/%3E %3Crect id=%22b%22 width=%22201%22 height=%22169%22 y=%2210%22 rx=%222%22/%3E %3Crect id=%22c%22 width=%2230%22 height=%222%22 x=%22135%22 y=%22158%22 rx=%221%22/%3E %3C/defs%3E %3Cg fill=%22none%22 fill-rule=%22evenodd%22%3E %3Cg transform=%22matrix%281 0 0 -1 0 13%29%22%3E %3Cuse fill=%22%23f8f9fa%22 xlink:href=%22%23a%22/%3E %3Crect width=%22199%22 height=%2211%22 x=%221%22 y=%221%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3C/g%3E %3Cuse fill=%22%23fff%22 xlink:href=%22%23b%22/%3E %3Crect width=%22199%22 height=%22167%22 x=%221%22 y=%2211%22 stroke=%22%23a2a9b1%22 stroke-width=%222%22 rx=%222%22/%3E %3Cg opacity=%22.4%22 fill=%22%2372777d%22 transform=%22translate%2867 35%29%22%3E %3Crect width=%2273%22 height=%222%22 y=%227%22 fill=%22%23c8ccd1%22 rx=%221%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2231%22 rx=%221%22/%3E %3Crect width=%2232%22 height=%222%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2273%22 height=%222%22 x=%2235%22 y=%2285%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 x=%2291%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2268%22 height=%222%22 x=%2220%22 y=%2245%22 rx=%221%22/%3E %3Crect width=%2217%22 height=%222%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2272%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2249%22 height=%222%22 x=%2220%22 y=%2278%22 rx=%221%22/%3E %3Crect width=%2224%22 height=%222%22 x=%2284%22 y=%2231%22 rx=%221%22 transform=%22matrix%28-1 0 0 1 192 0%29%22/%3E %3Crect width=%2281%22 height=%222%22 y=%2266%22 rx=%221%22/%3E %3Crect width=%2214%22 height=%222%22 x=%2254%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2237%22 height=%222%22 x=%2271%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 y=%2224%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2259%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2252%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2292%22 rx=%221%22/%3E %3Crect width=%22108%22 height=%222%22 y=%2238%22 rx=%221%22/%3E %3Crect width=%2251%22 height=%222%22 rx=%221%22/%3E %3C/g%3E %3Crect width=%2230%22 height=%222%22 x=%2267%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Crect width=%2230%22 height=%222%22 x=%2299%22 y=%22158%22 fill=%22%2372777d%22 opacity=%22.4%22 rx=%221%22/%3E %3Cuse fill=%22%2336c%22 xlink:href=%22%23c%22/%3E %3Crect width=%2233%22 height=%225%22 x=%22133.5%22 y=%22156.5%22 stroke=%22%23ffc057%22 stroke-opacity=%22.447%22 stroke-width=%223%22 rx=%222.5%22/%3E %3Ccircle cx=%2234%22 cy=%2249%22 r=%2219%22 fill=%22%23eaecf0%22/%3E %3Cg fill=%22%23a2a9b1%22 transform=%22translate%285 5%29%22%3E %3Ccircle cx=%221.5%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%226%22 cy=%221.5%22 r=%221.5%22/%3E %3Ccircle cx=%2210.5%22 cy=%221.5%22 r=%221.5%22/%3E %3C/g%3E %3Cpath stroke=%22%23ff00af%22 d=%22M174.5 159.5h54.01%22 stroke-linecap=%22square%22/%3E %3C/g%3E %3C/svg%3E")}.mw-ui-icon-preview-disambiguation:before{background-image:url(/w/load.php?modules=ext.popups.images&image=preview-disambiguation&format=rasterized&lang=en&skin=vector&version=0mti6id);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%222 2 20 20%22%3E %3Cg fill=%22%23c8ccd1%22%3E %3Cpath d=%22M11 12h4V7h-4v5zm-5 2h9v-1H6v1zm0 2h9v-1H6v1zm0 2h9v-1H6v1zm4-9H6v1h4V9zm0 2H6v1h4v-1zm0-4H6v1h4V7zM4 5h13v16H7c-1.7 0-3-1.3-3-3V5z%22/%3E %3Cpath fill-rule=%22evenodd%22 d=%22M18 4v14h2V2H7v2%22/%3E %3C/g%3E %3C/svg%3E")}</style><style>
.suggestions a.mw-searchSuggest-link,.suggestions a.mw-searchSuggest-link:hover,.suggestions a.mw-searchSuggest-link:active,.suggestions a.mw-searchSuggest-link:focus{color:#000;text-decoration:none}.suggestions-result-current a.mw-searchSuggest-link,.suggestions-result-current a.mw-searchSuggest-link:hover,.suggestions-result-current a.mw-searchSuggest-link:active,.suggestions-result-current a.mw-searchSuggest-link:focus{color:#fff}.suggestions a.mw-searchSuggest-link .special-query{ overflow:hidden;text-overflow:ellipsis;white-space:nowrap}
.mw-mmv-overlay{position:fixed;top:0;left:0;right:0;bottom:0;z-index:1000;background-color:#000}body.mw-mmv-lightbox-open{overflow-y:auto;  }body.mw-mmv-lightbox-open #mw-page-base,body.mw-mmv-lightbox-open #mw-head-base,body.mw-mmv-lightbox-open #mw-navigation,body.mw-mmv-lightbox-open #content,body.mw-mmv-lightbox-open #footer,body.mw-mmv-lightbox-open #globalWrapper{ display:none}body.mw-mmv-lightbox-open > *{ display:none}body.mw-mmv-lightbox-open > .mw-mmv-overlay,body.mw-mmv-lightbox-open > .mw-mmv-wrapper{display:block}.mw-mmv-filepage-buttons{margin-top:5px}.mw-mmv-filepage-buttons .mw-mmv-view-expanded,.mw-mmv-filepage-buttons .mw-mmv-view-config{display:block;line-height:inherit}.mw-mmv-filepage-buttons .mw-mmv-view-expanded.mw-ui-icon:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E %3Cpath d=%22M851.2 71.6L690.7 232.1l-40.1-40.3-9.6 164.8 164.8-9.3-40.3-40.4L926 146.4l58.5 58.5L997.6 0 792.7 13.1%22/%3E %3Cpath d=%22M769.6 89.3H611.9l70.9 70.8 7.9 7.5m-47.1 234.6l-51.2 3 3-51.2 9.4-164.4 5.8-100.3H26.4V768h883.1V387l-100.9 5.8-165 9.4zM813.9 678H113.6l207.2-270.2 31.5-12.9L548 599.8l105.9-63.2 159.8 140.8.2.6zm95.6-291.9V228l-79.1 78.9 7.8 7.9%22/%3E %3C/svg%3E")}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before{background-image:url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 1024 768%22%3E %3Cpath d=%22M897 454.6V313.4L810.4 299c-6.4-23.3-16-45.7-27.3-65.8l50.5-71.4-99.4-100.2-71.4 50.5c-20.9-11.2-42.5-20.9-65.8-27.3L582.6-1H441.4L427 85.6c-23.3 6.4-45.7 16-65.8 27.3l-71.4-50.5-100.3 99.5 50.5 71.4c-11.2 20.9-20.9 42.5-27.3 66.6L127 313.4v141.2l85.8 14.4c6.4 23.3 16 45.7 27.3 66.6L189.6 607l99.5 99.5 71.4-50.5c20.9 11.2 42.5 20.9 66.6 27.3l14.4 85.8h141.2l14.4-86.6c23.3-6.4 45.7-16 65.8-27.3l71.4 50.5 99.5-99.5-50.5-71.4c11.2-20.9 20.9-42.5 27.3-66.6l86.4-13.6zm-385 77c-81.8 0-147.6-66.6-147.6-147.6 0-81.8 66.6-147.6 147.6-147.6S659.6 302.2 659.6 384 593.8 531.6 512 531.6z%22/%3E %3C/svg%3E");opacity:0.75}.mw-mmv-filepage-buttons .mw-mmv-view-config.mw-ui-icon:before:hover{opacity:1}.mw-mmv-button{background-color:transparent;min-width:0;border:0;padding:0;overflow-x:hidden;text-indent:-9999em}
@-webkit-keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-moz-keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@keyframes mwe-popups-fade-in-up{0%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-webkit-keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-moz-keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@keyframes mwe-popups-fade-in-down{0%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}100%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}}@-webkit-keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@-moz-keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@keyframes mwe-popups-fade-out-down{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,20px);-moz-transform:translate(0,20px);-ms-transform:translate(0,20px);transform:translate(0,20px)}}@-webkit-keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}@-moz-keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}@keyframes mwe-popups-fade-out-up{0%{opacity:1;-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}100%{opacity:0;-webkit-transform:translate(0,-20px);-moz-transform:translate(0,-20px);-ms-transform:translate(0,-20px);transform:translate(0,-20px)}}.mwe-popups-fade-in-up{-webkit-animation:mwe-popups-fade-in-up 0.2s ease forwards;-moz-animation:mwe-popups-fade-in-up 0.2s ease forwards;animation:mwe-popups-fade-in-up 0.2s ease forwards}.mwe-popups-fade-in-down{-webkit-animation:mwe-popups-fade-in-down 0.2s ease forwards;-moz-animation:mwe-popups-fade-in-down 0.2s ease forwards;animation:mwe-popups-fade-in-down 0.2s ease forwards}.mwe-popups-fade-out-down{-webkit-animation:mwe-popups-fade-out-down 0.2s ease forwards;-moz-animation:mwe-popups-fade-out-down 0.2s ease forwards;animation:mwe-popups-fade-out-down 0.2s ease forwards}.mwe-popups-fade-out-up{-webkit-animation:mwe-popups-fade-out-up 0.2s ease forwards;-moz-animation:mwe-popups-fade-out-up 0.2s ease forwards;animation:mwe-popups-fade-out-up 0.2s ease forwards}   #mwe-popups-settings{z-index:1000;background:#fff;width:420px;border:1px solid #a2a9b1;box-shadow:0 2px 2px 0 rgba(0,0,0,0.25);border-radius:2px;font-size:14px}#mwe-popups-settings header{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;border-bottom:1px solid #c8ccd1;position:relative;display:table;width:100%;padding:5px 7px 5px 0}#mwe-popups-settings header > div{display:table-cell;width:3.5em;vertical-align:middle;cursor:pointer}#mwe-popups-settings header h1{margin-bottom:0.6em;padding-top:0.5em;border:0;width:100%;font-family:sans-serif;font-size:18px;font-weight:bold;text-align:center}#mwe-popups-settings .mwe-ui-icon-popups-close{opacity:0.87;-webkit-transition:opacity 100ms;-moz-transition:opacity 100ms;transition:opacity 100ms}#mwe-popups-settings .mwe-ui-icon-popups-close:hover{opacity:0.73}#mwe-popups-settings .mwe-ui-icon-popups-close:active{opacity:1}#mwe-popups-settings main{display:block;width:350px;padding:32px 0 24px;margin:0 auto}#mwe-popups-settings main p{color:#54595d;font-size:17px;margin:16px 0 0}#mwe-popups-settings main p:first-child{margin-top:0}#mwe-popups-settings main form img,#mwe-popups-settings main form input,#mwe-popups-settings main form label{vertical-align:top}#mwe-popups-settings main form img{margin-right:60px}#mwe-popups-settings main form input{display:inline-block;margin:0 10px 0 0;padding:0}#mwe-popups-settings main form label{font-size:13px;display:inline-block;line-height:16px;width:300px}#mwe-popups-settings main form label > span{color:#000;font-size:18px;font-weight:bold;display:block;margin-bottom:5px;line-height:18px}.mwe-popups-settings-help{font-size:13px;font-weight:800;margin:40px;position:relative}.mwe-popups-settings-help .mw-ui-icon:before,.mwe-popups-settings-help .mw-ui-icon{height:140px;width:180px;max-width:none;margin:0}.mwe-popups-settings-help p{left:180px;bottom:20px;position:absolute}.mwe-popups{background:#fff;position:absolute;z-index:110;-webkit-box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px #a2a9b1;box-shadow:0 30px 90px -20px rgba(0,0,0,0.3),0 0 1px #a2a9b1;padding:0;display:none;font-size:14px;line-height:20px;min-width:300px;border-radius:2px; }.mwe-popups .mw-ui-icon{font-size:16px}.mwe-popups .mw-ui-icon-preview-disambiguation,.mwe-popups .mw-ui-icon-preview-generic{margin:21px 0 8px 0}.mwe-popups .mwe-popups-container{color:#222222;margin-top:-9px;padding-top:9px;text-decoration:none}.mwe-popups .mwe-popups-container footer{padding:16px;margin:0;font-size:10px;position:absolute;bottom:0;left:0}.mwe-popups .mwe-popups-extract{margin:16px;display:block;color:#222222;text-decoration:none;position:relative;   }.mwe-popups .mwe-popups-extract:hover{text-decoration:none}.mwe-popups .mwe-popups-extract:after{content:' ';position:absolute;bottom:0;width:25%;height:20px;background-color:transparent}.mwe-popups .mwe-popups-extract[dir='ltr']:after{ right:0; background-image:-webkit-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:-moz-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:-o-linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%); background-image:linear-gradient(to right,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract[dir='rtl']:after{ left:0; background-image:-webkit-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:-moz-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:-o-linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%); background-image:linear-gradient(to left,rgba(255,255,255,0),#ffffff 50%)}.mwe-popups .mwe-popups-extract p{margin:0}.mwe-popups .mwe-popups-extract ul,.mwe-popups .mwe-popups-extract ol,.mwe-popups .mwe-popups-extract li,.mwe-popups .mwe-popups-extract dl,.mwe-popups .mwe-popups-extract dd,.mwe-popups .mwe-popups-extract dt{margin-top:0;margin-bottom:0}.mwe-popups svg{overflow:hidden}.mwe-popups.mwe-popups-is-tall{width:450px}.mwe-popups.mwe-popups-is-tall > div > a > svg{vertical-align:middle}.mwe-popups.mwe-popups-is-tall .mwe-popups-extract{width:215px;height:180px;overflow:hidden;float:left}.mwe-popups.mwe-popups-is-tall footer{width:215px;left:0}.mwe-popups.mwe-popups-is-not-tall{width:320px}.mwe-popups.mwe-popups-is-not-tall .mwe-popups-extract{min-height:40px;max-height:140px;overflow:hidden;margin-bottom:47px;padding-bottom:0}.mwe-popups.mwe-popups-is-not-tall footer{width:290px}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract{min-height:auto;padding-top:4px;margin-bottom:60px;margin-top:0}.mwe-popups.mwe-popups-type-generic .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-read-link{font-weight:bold;font-size:12px}.mwe-popups.mwe-popups-type-generic .mwe-popups-extract:hover + footer .mwe-popups-read-link,.mwe-popups.mwe-popups-type-disambiguation .mwe-popups-extract:hover + footer .mwe-popups-read-link{text-decoration:underline}.mwe-popups.mwe-popups-no-image-pointer:before{content:'';position:absolute;border:8px solid transparent;border-top:0;border-bottom:8px solid #a2a9b1;top:-8px;left:10px}.mwe-popups.mwe-popups-no-image-pointer:after{content:'';position:absolute;border:11px solid transparent;border-top:0;border-bottom:11px solid #ffffff;top:-7px;left:7px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer:before{left:auto;right:10px}.mwe-popups.flipped-x.mwe-popups-no-image-pointer:after{left:auto;right:7px}.mwe-popups.mwe-popups-image-pointer:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:9px;z-index:111}.mwe-popups.mwe-popups-image-pointer:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px;left:6px;z-index:112}.mwe-popups.mwe-popups-image-pointer.flipped-x:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:273px}.mwe-popups.mwe-popups-image-pointer.flipped-x:after{content:'';position:absolute;border:12px solid transparent;border-top:0;border-bottom:12px solid #ffffff;top:-8px;left:269px}.mwe-popups.mwe-popups-image-pointer .mwe-popups-extract{padding-top:16px;margin-top:200px}.mwe-popups.mwe-popups-image-pointer > div > a > svg{margin-top:-8px;position:absolute;z-index:113;left:0}.mwe-popups.flipped-x.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x.mwe-popups-is-tall:before{content:'';position:absolute;border:9px solid transparent;border-top:0;border-bottom:9px solid #a2a9b1;top:-9px;left:420px;z-index:111}.mwe-popups.flipped-x.mwe-popups-is-tall > div > a > svg{margin:0;margin-top:-8px;margin-bottom:-7px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-x-y:before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:272px;z-index:111}.mwe-popups.flipped-x-y:after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px;left:269px;z-index:112}.mwe-popups.flipped-x-y.mwe-popups-is-tall{min-height:242px}.mwe-popups.flipped-x-y.mwe-popups-is-tall:before{content:'';position:absolute;border:9px solid transparent;border-bottom:0;border-top:9px solid #a2a9b1;bottom:-9px;left:420px}.mwe-popups.flipped-x-y.mwe-popups-is-tall:after{content:'';position:absolute;border:12px solid transparent;border-bottom:0;border-top:12px solid #ffffff;bottom:-8px;left:417px}.mwe-popups.flipped-x-y.mwe-popups-is-tall > div > a > svg{margin:0;margin-bottom:-9px;position:absolute;z-index:113;right:0}.mwe-popups.flipped-y:before{content:'';position:absolute;border:8px solid transparent;border-bottom:0;border-top:8px solid #a2a9b1;bottom:-8px;left:10px}.mwe-popups.flipped-y:after{content:'';position:absolute;border:11px solid transparent;border-bottom:0;border-top:11px solid #ffffff;bottom:-7px;left:7px}.mwe-popups-is-tall polyline{-webkit-transform:translate(0,0);-moz-transform:translate(0,0);-ms-transform:translate(0,0);transform:translate(0,0)}.mwe-popups-is-tall.flipped-x-y polyline{-webkit-transform:translate(0,-8px);-moz-transform:translate(0,-8px);-ms-transform:translate(0,-8px);transform:translate(0,-8px)}.mwe-popups-is-tall.flipped-x polyline{-webkit-transform:translate(0,8px);-moz-transform:translate(0,8px);-ms-transform:translate(0,8px);transform:translate(0,8px)}.rtl .mwe-popups-is-tall polyline{-webkit-transform:translate(-100%,0);-moz-transform:translate(-100%,0);-ms-transform:translate(-100%,0);transform:translate(-100%,0)}.rtl .mwe-popups-is-tall.flipped-x-y polyline{-webkit-transform:translate(-100%,-8px);-moz-transform:translate(-100%,-8px);-ms-transform:translate(-100%,-8px);transform:translate(-100%,-8px)}.rtl .mwe-popups-is-tall.flipped-x polyline{-webkit-transform:translate(-100%,8px);-moz-transform:translate(-100%,8px);-ms-transform:translate(-100%,8px);transform:translate(-100%,8px)}.mwe-popups-settings-icon{display:block;overflow:hidden;font-size:16px;width:1.5em;height:1.5em;padding:3px;float:right;margin:4px 4px 2px 4px;text-indent:-1em;border-radius:2px}.mwe-popups-settings-icon:hover{background-color:#eaecf0}.mwe-popups-settings-icon:active{background-color:#c8ccd1}.mwe-popups .mwe-popups-title{display:block;font-weight:bold;margin:0 16px}.mwe-popups-overlay{background-color:rgba(255,255,255,0.9);z-index:999;position:fixed;height:100%;width:100%;top:0;bottom:0;left:0;right:0;display:flex;justify-content:center;align-items:center}#mwe-popups-svg{position:absolute;top:-1000px}
.ve-init-mw-tempWikitextEditorWidget{border:0;padding:0;color:inherit;line-height:1.5em;width:100%; }.ve-init-mw-tempWikitextEditorWidget:focus{outline:0;padding:0}.ve-init-mw-tempWikitextEditorWidget::selection{background:rgba(109,169,247,0.5); }
#p-lang .body ul .uls-trigger,#p-lang .pBody ul .uls-trigger{background-image:none;padding:0} .mw-interlanguage-selector,.mw-interlanguage-selector:active{cursor:pointer;padding:4px 6px 4px 25px;font-size:13px;font-weight:normal;background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/compact-links-trigger.png?b0c8e);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2218%22 height=%2218%22 viewBox=%220 0 24 24%22%3E %3Cpath fill=%22%2372777d%22 d=%22M13 19l.8-3h5.3l.9 3h2.2L18 6h-3l-4.2 13H13zm3.5-11l2 6h-4l2-6zM5 4l.938 1.906H1V8h1.594C3.194 9.8 4 11.206 5 12.406c-1.1.7-4.313 1.781-4.313 1.781L2 16s3.487-1.387 4.688-2.188c1 .7 2.319 1.188 3.719 1.688l.594-2c-1-.3-1.988-.688-2.688-1.188 1.1-1.1 1.9-2.506 2.5-4.406h2.188l.5-2H7.938L7 4H5zm-.188 4h3.781c-.4 1.3-.906 2-1.906 3-1.1-1-1.475-1.7-1.875-3z%22/%3E %3C/svg%3E");background-size:18px;background-repeat:no-repeat;background-position:left 4px center;margin:4px 0;text-align:left}.mw-interlanguage-selector:active,.mw-interlanguage-selector.selector-open{background-color:#c8ccd1;color:#54595d}.interlanguage-uls-menu:before,.interlanguage-uls-menu:after{border-top:10px solid transparent;border-bottom:10px solid transparent;display:inline-block; top:17px;position:absolute;content:''}.interlanguage-uls-menu.selector-right:before{ border-left:10px solid #c8ccd1; right:-11px}.interlanguage-uls-menu.selector-right:after{ border-left:10px solid #fff; right:-10px}.interlanguage-uls-menu.selector-left:before{ border-right:10px solid #c8ccd1; left:-11px}.interlanguage-uls-menu.selector-left:after{ border-right:10px solid #fff; left:-10px}
#uls-settings-block{background-color:#f8f9fa;border-top:1px solid #c8ccd1;padding-left:10px;line-height:1.2em;border-radius:0 0 2px 2px}#uls-settings-block > button{background:left top transparent no-repeat;background-size:20px auto;color:#54595d;display:inline-block;margin:8px 15px;border:0;padding:0 0 0 26px;font-size:medium;cursor:pointer}#uls-settings-block > button:hover{color:#222}#uls-settings-block > button.display-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/display.png?d25f1);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Cpath fill=%22%23222%22 d=%22M.002 2.275V15.22h8.405c.535 1.624-.975 1.786-1.902 2.505 0 0 2.293-.024 3.439-.024 1.144 0 3.432.024 3.432.024-.905-.688-2.355-.868-1.902-2.505h8.527V2.275h-20zm6.81 1.84h.797l3.313 8.466H9.879L8.836 9.943H5.462l-1.043 2.638h-.982zm.368 1.104c-.084.369-.211.785-.368 1.227L5.83 9.023h2.699l-.982-2.577c-.128-.33-.234-.747-.368-1.227zm7.117.982c.753 0 1.295.157 1.656.491.365.334.552.858.552 1.595v4.294h-.675l-.184-.859h-.062c-.315.396-.605.655-.92.798-.311.138-.758.184-1.227.184-.626 0-1.115-.168-1.472-.491-.353-.323-.491-.754-.491-1.35 0-1.275 1.028-1.963 3.068-2.025h1.043v-.429c0-.495-.091-.87-.307-1.104-.211-.238-.574-.307-1.043-.307-.526 0-1.115.107-1.779.429l-.307-.675a4.748 4.748 0 0 1 1.043-.429 4.334 4.334 0 0 1 1.104-.123zm.307 3.313c-.761.027-1.318.157-1.656.368-.334.207-.491.54-.491.982 0 .346.1.617.307.798.211.181.544.245.92.245.595 0 1.012-.164 1.35-.491.342-.326.552-.762.552-1.35v-.552z%22/%3E %3C/svg%3E")}#uls-settings-block > button.input-settings-block{background-image:url(/w/extensions/UniversalLanguageSelector/resources/images/input.png?aea9e);background-image:linear-gradient(transparent,transparent),url("data:image/svg+xml,%3Csvg xmlns=%22http://www.w3.org/2000/svg%22 width=%2220%22 height=%2220%22 viewBox=%220 0 20 20%22%3E %3Cpath fill=%22%23222%22 d=%22M9 1.281c-.124.259-.185.599-.5.688-.55.081-1.133.018-1.688 0-.866-.032-1.733-.148-2.594 0-.588.157-.953.727-1.188 1.25-.178.416-.271.836-.344 1.281H-.002V16h20V4.5H3.654c.109-.52.203-1.057.563-1.469.222-.231.587-.17.875-.188 1.212.003 2.415.179 3.625.063.463-.058.812-.455.969-.875l.188-.438-.875-.313zM1.875 7.125h1.563c.094 0 .188.093.188.188v1.531a.201.201 0 0 1-.188.188H1.875c-.094 0-.156-.093-.156-.188V7.313c0-.094.062-.188.156-.188zm2.844 0h1.563c.094 0 .156.093.156.188v1.531c0 .094-.062.188-.156.188H4.719c-.094 0-.156-.093-.156-.188V7.313c0-.094.062-.188.156-.188zm2.844 0h1.563c.094 0 .156.093.156.188v1.531c0 .094-.062.188-.156.188H7.563a.201.201 0 0 1-.188-.188V7.313c0-.094.093-.188.188-.188zm2.813 0h1.563c.094 0 .188.093.188.188v1.531a.201.201 0 0 1-.188.188h-1.563c-.094 0-.156-.093-.156-.188V7.313c0-.094.062-.188.156-.188zm2.844 0h1.563c.094 0 .156.093.156.188v1.531c0 .094-.062.188-.156.188H13.22c-.094 0-.156-.093-.156-.188V7.313c0-.094.062-.188.156-.188zm2.844 0h1.531c.094 0 .188.093.188.188v1.531a.201.201 0 0 1-.188.188h-1.531a.201.201 0 0 1-.188-.188V7.313c0-.094.093-.188.188-.188zm-12.844 3h1.563c.094 0 .156.093.156.188v1.563c0 .094-.062.156-.156.156H3.22c-.094 0-.156-.062-.156-.156v-1.563c0-.094.062-.188.156-.188zm2.906 0h1.563c.094 0 .188.093.188.188v1.563c0 .094-.093.156-.188.156H6.126c-.094 0-.156-.062-.156-.156v-1.563c0-.094.062-.188.156-.188zm2.938 0h1.531c.094 0 .188.093.188.188v1.563c0 .094-.093.156-.188.156H9.064c-.094 0-.188-.062-.188-.156v-1.563c0-.094.093-.188.188-.188zm2.906 0h1.563c.094 0 .156.093.156.188v1.563c0 .094-.062.156-.156.156H11.97c-.094 0-.188-.062-.188-.156v-1.563c0-.094.093-.188.188-.188zm2.906 0h1.563c.094 0 .156.093.156.188v1.563c0 .094-.062.156-.156.156h-1.563c-.094 0-.156-.062-.156-.156v-1.563c0-.094.062-.188.156-.188zM4.001 13.688h12c.088 0 .156.068.156.156v.844a.154.154 0 0 1-.156.156h-12a.154.154 0 0 1-.156-.156v-.844c0-.088.068-.156.156-.156z%22/%3E %3C/svg%3E")}</style><style>
.ve-activated .ve-init-mw-desktopArticleTarget-editableContent #toc,.ve-activated #siteNotice,.ve-activated .mw-indicators,.ve-activated #t-print,.ve-activated #t-permalink,.ve-activated #p-coll-print_export,.ve-activated #t-cite,.ve-deactivating .ve-ui-surface,.ve-active .ve-init-mw-desktopArticleTarget-editableContent,.ve-active .ve-init-mw-tempWikitextEditorWidget{display:none} .ve-activating .ve-ui-surface{height:0;padding:0 !important; overflow:hidden} .ve-loading #content > :not(.ve-init-mw-desktopArticleTarget-loading-overlay), .ve-activated .ve-init-mw-desktopArticleTarget-uneditableContent{pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;opacity:0.5}.ve-activated #catlinks{cursor:pointer}.ve-activated #catlinks a{opacity:1} .ve-activated #content{position:relative} .ve-init-mw-desktopArticleTarget-loading-overlay{position:absolute;top:1.25em;left:0;right:0;z-index:1;margin-top:-0.5em}.ve-init-mw-desktopArticleTarget-progress{height:1em;overflow:hidden;margin:0 25%}.ve-init-mw-desktopArticleTarget-progress-bar{height:1em;width:0}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{transition:height 250ms ease;height:0; } .oo-ui-element-hidden{display:none !important; } .mw-editsection{white-space:nowrap; unicode-bidi:-moz-isolate;unicode-bidi:-webkit-isolate;unicode-bidi:isolate}.mw-editsection-divider{color:#54595d} .ve-init-mw-desktopArticleTarget-progress{height:0.75em;border:1px solid #36c;background:#fff;border-radius:2px;box-shadow:0 0.1em 0 0 rgba(0,0,0,0.15)}.ve-init-mw-desktopArticleTarget-progress-bar{height:0.75em;background:#36c}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{border-bottom:1px solid #c8ccd1;box-shadow:0 1px 1px 0 rgba(0,0,0,0.1)}.ve-init-mw-desktopArticleTarget-toolbarPlaceholder-open{height:40px} .ve-init-mw-desktopArticleTarget-toolbar,.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{font-size:0.875em; margin:-1.14em -1.14em 1.14em -1.14em; }@media screen and (min-width:982px){.ve-init-mw-desktopArticleTarget-toolbar,.ve-init-mw-desktopArticleTarget-toolbarPlaceholder{ margin:-1.43em -1.71em 1.43em -1.71em}}</style><meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="./Long short-term memory - Wikipedia_files/load(2).php">
<link rel="stylesheet" href="./Long short-term memory - Wikipedia_files/load(3).php">
<meta name="generator" content="MediaWiki 1.33.0-wmf.6">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-crossorigin">
<meta name="referrer" content="origin-when-cross-origin">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/1200px-The_LSTM_cell.png">
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Long_short-term_memory">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit">
<link rel="edit" title="Edit this page" href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit">
<link rel="apple-touch-icon" href="https://en.wikipedia.org/static/apple-touch/wikipedia.png">
<link rel="shortcut icon" href="https://en.wikipedia.org/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="https://en.wikipedia.org/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://en.wikipedia.org/w/api.php?action=rsd">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/">
<link rel="canonical" href="https://en.wikipedia.org/wiki/Long_short-term_memory">
<link rel="dns-prefetch" href="https://login.wikimedia.org/">
<link rel="dns-prefetch" href="https://meta.wikimedia.org/">
<!--[if lt IE 9]><script src="/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Long_short-term_memory rootpage-Long_short-term_memory skin-vector action-view" data-gr-c-s-loaded="true">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="siteNotice" class="mw-body-content"><div id="centralNotice"></div><!-- CentralNotice --></div><div class="mw-indicators mw-body-content">
</div>
<h1 id="firstHeading" class="firstHeading" lang="en">Long short-term memory</h1>			<div id="bodyContent" class="mw-body-content">
				<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>				<div id="contentSub"></div>
				<div id="jump-to-nav"></div>				<a class="mw-jump-link" href="https://en.wikipedia.org/wiki/Long_short-term_memory#mw-head">Jump to navigation</a>
				<a class="mw-jump-link" href="https://en.wikipedia.org/wiki/Long_short-term_memory#p-search">Jump to search</a>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br><a href="https://en.wikipedia.org/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="https://en.wikipedia.org/wiki/File:Kernel_Machine.svg" class="image"><img alt="Kernel Machine.svg" src="./Long short-term memory - Wikipedia_files/220px-Kernel_Machine.svg.png" width="220" height="100" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" data-file-width="512" data-file-height="233"></a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame1"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems<a class="NavToggle" id="NavToggle1" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="https://en.wikipedia.org/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="https://en.wikipedia.org/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="https://en.wikipedia.org/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="https://en.wikipedia.org/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame2"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br><style data-mw-deduplicate="TemplateStyles:r865336399">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="https://en.wikipedia.org/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&nbsp;• <b><a href="https://en.wikipedia.org/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div><a class="NavToggle" id="NavToggle2" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="https://en.wikipedia.org/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="https://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="https://en.wikipedia.org/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="https://en.wikipedia.org/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame3"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a><a class="NavToggle" id="NavToggle3" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a href="https://en.wikipedia.org/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="https://en.wikipedia.org/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br><a href="https://en.wikipedia.org/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="https://en.wikipedia.org/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a href="https://en.wikipedia.org/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame4"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a><a class="NavToggle" id="NavToggle4" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="https://en.wikipedia.org/wiki/Canonical_correlation_analysis" class="mw-redirect" title="Canonical correlation analysis">CCA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="https://en.wikipedia.org/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame5"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a><a class="NavToggle" id="NavToggle5" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="https://en.wikipedia.org/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame6"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a><a class="NavToggle" id="NavToggle6" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="https://en.wikipedia.org/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame7"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Artificial_neural_networks" class="mw-redirect" title="Artificial neural networks">Artificial neural networks</a><a class="NavToggle" id="NavToggle7" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="https://en.wikipedia.org/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a class="mw-selflink selflink">LSTM</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a>)</li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="https://en.wikipedia.org/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="https://en.wikipedia.org/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame8"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a><a class="NavToggle" id="NavToggle8" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="https://en.wikipedia.org/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame9"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory<a class="NavToggle" id="NavToggle9" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Bias-variance_dilemma" class="mw-redirect" title="Bias-variance dilemma">Bias-variance dilemma</a></li>
<li><a href="https://en.wikipedia.org/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="https://en.wikipedia.org/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame10"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues<a class="NavToggle" id="NavToggle10" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a></li>
<li><a href="https://en.wikipedia.org/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="https://en.wikipedia.org/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="https://en.wikipedia.org/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame11"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a><a class="NavToggle" id="NavToggle11" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0" id="NavFrame12"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles<a class="NavToggle" id="NavToggle12" href="https://en.wikipedia.org/wiki/Long_short-term_memory#">[show]</a></div><div class="NavContent" style="font-size: 105%; padding: 0.2em 0px 0.4em; text-align: center; display: none;"><div class="hlist">
<ul><li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research" class="mw-redirect" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="https://en.wikipedia.org/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td class="plainlist" style="padding:0.3em 0.4em 0.3em;font-weight:bold;border-top: 1px solid #aaa; border-bottom: 1px solid #aaa;border-top:1px solid #aaa;border-bottom:1px solid #aaa;">
<ul><li><a href="https://en.wikipedia.org/wiki/File:Portal-puzzle.svg" class="image"><img alt="Portal-puzzle.svg" src="./Long short-term memory - Wikipedia_files/16px-Portal-puzzle.svg.png" width="16" height="14" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/24px-Portal-puzzle.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/f/fd/Portal-puzzle.svg/32px-Portal-puzzle.svg.png 2x" data-file-width="32" data-file-height="28"></a> <a href="https://en.wikipedia.org/wiki/Portal:Machine_learning" title="Portal:Machine learning">Machine learning portal</a></li></ul></td></tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="https://en.wikipedia.org/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="https://en.wikipedia.org/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<div class="thumb tright"><div class="thumbinner" style="width:172px;"><a href="https://en.wikipedia.org/wiki/File:The_LSTM_cell.png" class="image"><img alt="" src="./Long short-term memory - Wikipedia_files/170px-The_LSTM_cell.png" width="170" height="112" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/255px-The_LSTM_cell.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3b/The_LSTM_cell.png/340px-The_LSTM_cell.png 2x" data-file-width="2014" data-file-height="1322"></a>  <div class="thumbcaption"><div class="magnify"><a href="https://en.wikipedia.org/wiki/File:The_LSTM_cell.png" class="internal" title="Enlarge"></a></div>The Long Short-Term Memory (LSTM) cell can process data sequentially and keep its hidden state through time.</div></div></div>
<p><b>Long short-term memory</b> (<b>LSTM</b>) units are units of a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" title="Recurrent neural network">recurrent neural network</a> (RNN). An RNN composed of LSTM units is often called an <i>LSTM network</i>. A common LSTM unit is composed of a <b>cell</b>, an <b>input gate</b>, an <b>output gate</b> and a <b>forget gate</b>. The cell remembers values over arbitrary time intervals and the three <i>gates</i> regulate the flow of information into and out of the cell.
</p><p>LSTM networks are well-suited to <a href="https://en.wikipedia.org/wiki/Classification_in_machine_learning" class="mw-redirect" title="Classification in machine learning">classifying</a>, <a href="https://en.wikipedia.org/wiki/Computer_data_processing" class="mw-redirect" title="">processing</a> and <a href="https://en.wikipedia.org/wiki/Predict" class="mw-redirect" title="Predict">making predictions</a> based on <a href="https://en.wikipedia.org/wiki/Time_series" title="Time series">time series</a> data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">vanishing</a> gradient problems that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, <a href="https://en.wikipedia.org/wiki/Hidden_Markov_models" class="mw-redirect" title="Hidden Markov models">hidden Markov models</a> and other sequence learning methods in numerous applications<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2017)">citation needed</span></a></i>]</sup>.
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none"><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Architectures"><span class="tocnumber">2</span> <span class="toctext">Architectures</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Variants"><span class="tocnumber">3</span> <span class="toctext">Variants</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#LSTM_with_a_forget_gate"><span class="tocnumber">3.1</span> <span class="toctext">LSTM with a forget gate</span></a>
<ul>
<li class="toclevel-3 tocsection-5"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Variables"><span class="tocnumber">3.1.1</span> <span class="toctext">Variables</span></a></li>
<li class="toclevel-3 tocsection-6"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Activation_functions"><span class="tocnumber">3.1.2</span> <span class="toctext">Activation functions</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-7"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Peephole_LSTM"><span class="tocnumber">3.2</span> <span class="toctext">Peephole LSTM</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Peephole_convolutional_LSTM"><span class="tocnumber">3.3</span> <span class="toctext">Peephole convolutional LSTM</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-9"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Training"><span class="tocnumber">4</span> <span class="toctext">Training</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#CTC_score_function"><span class="tocnumber">4.1</span> <span class="toctext">CTC score function</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Applications"><span class="tocnumber">5</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#See_also"><span class="tocnumber">6</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>LSTM was proposed in 1997 by <a href="https://en.wikipedia.org/wiki/Sepp_Hochreiter" title="Sepp Hochreiter">Sepp Hochreiter</a> and <a href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a><sup id="cite_ref-lstm1997_1-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-lstm1997-1">[1]</a></sup> and improved in 2000 by <a href="https://en.wikipedia.org/wiki/Felix_Gers" title="Felix Gers">Felix Gers</a>' team.<sup id="cite_ref-lstm2000_2-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-lstm2000-2">[2]</a></sup>
</p><p>Among other successes, LSTM achieved record results in natural language text compression,<sup id="cite_ref-3" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-3">[3]</a></sup> unsegmented connected <a href="https://en.wikipedia.org/wiki/Handwriting_recognition" title="Handwriting recognition">handwriting recognition</a><sup id="cite_ref-4" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-4">[4]</a></sup> and won the <a href="https://en.wikipedia.org/wiki/ICDAR" class="mw-redirect" title="ICDAR">ICDAR</a> handwriting competition (2009). LSTM networks were a major component of a network that achieved a record 17.7% <a href="https://en.wikipedia.org/wiki/Phoneme" title="Phoneme">phoneme</a> error rate on the classic <a href="https://en.wikipedia.org/wiki/TIMIT" title="TIMIT">TIMIT</a> natural speech dataset (2013).<sup id="cite_ref-5" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-5">[5]</a></sup>
</p><p>As of 2016, major technology companies including <a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a>, <a href="https://en.wikipedia.org/wiki/Apple_Inc." title="Apple Inc.">Apple</a>, and <a href="https://en.wikipedia.org/wiki/Microsoft" title="Microsoft">Microsoft</a> were using LSTM as fundamental components in new products.<sup id="cite_ref-6" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-6">[6]</a></sup> For example, Google used LSTM for speech recognition on the <a href="https://en.wikipedia.org/wiki/Smartphone" title="Smartphone">smartphone</a>,<sup id="cite_ref-Beau15_7-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-Beau15-7">[7]</a></sup><sup id="cite_ref-GoogleVoiceSearch_8-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-GoogleVoiceSearch-8">[8]</a></sup> for the smart assistant Allo<sup id="cite_ref-GoogleAllo_9-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-GoogleAllo-9">[9]</a></sup> and for <a href="https://en.wikipedia.org/wiki/Google_Translate" title="Google Translate">Google Translate</a>.<sup id="cite_ref-GoogleTranslate_10-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-GoogleTranslate-10">[10]</a></sup><sup id="cite_ref-WiredGoogleTranslate_11-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-WiredGoogleTranslate-11">[11]</a></sup> <a href="https://en.wikipedia.org/wiki/Apple_Inc." title="Apple Inc.">Apple</a> uses LSTM for the "Quicktype" function on the <a href="https://en.wikipedia.org/wiki/IPhone" title="IPhone">iPhone</a><sup id="cite_ref-AppleQuicktype_12-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-AppleQuicktype-12">[12]</a></sup><sup id="cite_ref-AppleQuicktype2_13-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-AppleQuicktype2-13">[13]</a></sup> and for <a href="https://en.wikipedia.org/wiki/Siri" title="Siri">Siri</a>.<sup id="cite_ref-AppleSiri_14-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-AppleSiri-14">[14]</a></sup> <a href="https://en.wikipedia.org/wiki/Amazon_Inc." class="mw-redirect" title="Amazon Inc.">Amazon</a> uses LSTM for <a href="https://en.wikipedia.org/wiki/Amazon_Alexa" title="Amazon Alexa">Amazon Alexa</a>.<sup id="cite_ref-AmazonAlexa_15-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-AmazonAlexa-15">[15]</a></sup>
</p><p>In 2017 researchers from <a href="https://en.wikipedia.org/wiki/Michigan_State_University" title="Michigan State University">Michigan State University</a>, <a href="https://en.wikipedia.org/wiki/IBM_Research" title="IBM Research">IBM Research</a>, and <a href="https://en.wikipedia.org/wiki/Cornell_University" title="Cornell University">Cornell University</a> published a study in the Knowledge Discovery and Data Mining (KDD) conference.<sup id="cite_ref-16" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-16">[16]</a></sup><sup id="cite_ref-17" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-17">[17]</a></sup><sup id="cite_ref-18" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-18">[18]</a></sup> Their study describes a novel neural network that performs better than the widely used long short-term memory neural network.
</p><p>Further in 2017 Microsoft reported reaching 95.1% recognition accuracy on the <a href="https://en.wikipedia.org/w/index.php?title=Switchboard_corpus&amp;action=edit&amp;redlink=1" class="new" title="Switchboard corpus (page does not exist)">Switchboard corpus</a>, incorporating a vocabulary of 165,000 words. The approach used "dialog session-based long-short-term memory".<sup id="cite_ref-19" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-19">[19]</a></sup>
</p>
<h2><span class="mw-headline" id="Architectures">Architectures</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=2" title="Edit section: Architectures">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are several architectures of LSTM units. A common architecture is composed of a memory <i>cell</i>, an <i>input gate</i>, an <i>output gate</i> and a <i>forget gate</i>.
</p><p>An LSTM <i>cell</i> takes an input and stores it for some period of time. This is equivalent to applying the <a href="https://en.wikipedia.org/wiki/Identity_function" title="Identity function">identity function</a> (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f(x)=x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)=x)}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/38e988b225c03bd01b0185e24b43827a1d821247" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.75ex; height:2.843ex;" alt="{\displaystyle f(x)=x)}"></span> to the input. Because the <a href="https://en.wikipedia.org/wiki/Derivative" title="Derivative">derivative</a> of the identity function is constant, when an LSTM network is trained with <a href="https://en.wikipedia.org/wiki/Backpropagation_through_time" title="Backpropagation through time">backpropagation through time</a>, the <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">gradient does not vanish</a>.
</p><p>The activation function of the LSTM <i>gates</i> is often the <a href="https://en.wikipedia.org/wiki/Logistic_function" title="Logistic function">logistic function</a>. Intuitively, the <i>input gate</i> controls the extent to which a new value flows into the cell, the <i>forget gate</i> controls the extent to which a value remains in the cell and the <i>output gate</i> controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit.
</p><p>There are connections into and out of the LSTM <i>gates</i>, a few of which are recurrent. The weights of these connections, which need to be learned during <a href="https://en.wikipedia.org/wiki/Supervised_learning" title="Supervised learning">training</a>, determine how the gates operate.
</p>
<h2><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=3" title="Edit section: Variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In the equations below, the lowercase variables represent vectors. Matrices <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle W_{q}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>q</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W_{q}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/d16355ad959593cf720b24fffe62d99af53d15d9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:3.182ex; height:2.843ex;" alt="{\displaystyle W_{q}}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle U_{q}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>U</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>q</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle U_{q}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/05e27486afb11613504d6d6b9f6bd72e322607c8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.576ex; height:2.843ex;" alt="{\displaystyle U_{q}}"></span> contain, respectively, the weights of the input and recurrent connections, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle q}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>q</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle q}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/06809d64fa7c817ffc7e323f85997f783dbdf71d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.07ex; height:2.009ex;" alt="q"></span> can either be the input gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="i"></span>, output gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0c1031f61947aa3d1cf3a70ec3e4904df2c3675d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="o"></span>, the forget gate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"></span> or the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"></span>, depending on the activation being calculated.
</p>
<h3><span class="mw-headline" id="LSTM_with_a_forget_gate">LSTM with a forget gate</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=4" title="Edit section: LSTM with a forget gate">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The compact forms of the equations for the forward pass of an LSTM unit with a forget gate are:<sup id="cite_ref-lstm1997_1-1" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-lstm1997-1">[1]</a></sup><sup id="cite_ref-lstm2000_2-1" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-lstm2000-2">[2]</a></sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/2db2cba6a0d878e13932fa27ce6f3fb71ad99cf1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -7.338ex; width:44.566ex; height:15.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}"></span></dd></dl>
<p>where the initial values are <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{0}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{0}=0}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/29af3d4e887815bb3b9b9eab4f7540a376fccd73" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.322ex; height:2.509ex;" alt="c_{0}=0"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle h_{0}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{0}=0}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/14a294b6cf9cbde4c37efd966913a63d316e615c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.654ex; height:2.509ex;" alt="{\displaystyle h_{0}=0}"></span> and the operator <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \circ }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>∘<!-- ∘ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \circ }</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/99add39d2b681e2de7ff62422c32704a05c7ec31" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.125ex; margin-bottom: -0.297ex; width:1.162ex; height:1.509ex;" alt="\circ "></span> denotes the <a href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)" title="Hadamard product (matrices)">Hadamard product</a> (element-wise product). The subscript <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"></span> indexes the time step.
</p>
<h4><span class="mw-headline" id="Variables">Variables</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=5" title="Edit section: Variables">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle x_{t}\in \mathbb {R} ^{d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{t}\in \mathbb {R} ^{d}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/d528d57c5517e90795e0a6d6760463564236fee7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.766ex; height:3.009ex;" alt="{\displaystyle x_{t}\in \mathbb {R} ^{d}}"></span>: input vector to the LSTM unit</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/02547735a64d79c553b23eaf3aeaaaf2fcde6eba" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.663ex; height:3.009ex;" alt="{\displaystyle f_{t}\in \mathbb {R} ^{h}}"></span>: forget gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/abb830b2d64edaa2aa92edaeccdcb027afa7344e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.326ex; height:3.009ex;" alt="{\displaystyle i_{t}\in \mathbb {R} ^{h}}"></span>: input gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle o_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/25b8c014b13f62fbe82f9a277a71f6a10c2ae330" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.651ex; height:3.009ex;" alt="{\displaystyle o_{t}\in \mathbb {R} ^{h}}"></span>: output gate's activation vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle h_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/cf6b05b4bd0106b70d036400f1ddd3ae54be2689" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.863ex; height:3.009ex;" alt="{\displaystyle h_{t}\in \mathbb {R} ^{h}}"></span>: hidden state vector also known as output vector of the LSTM unit</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t}\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/65d6f2af820422ed59a0f14af91eee7498ebc4a2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:7.531ex; height:3.009ex;" alt="{\displaystyle c_{t}\in \mathbb {R} ^{h}}"></span>: cell state vector</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle W\in \mathbb {R} ^{h\times d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
            <mo>×<!-- × --></mo>
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W\in \mathbb {R} ^{h\times d}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/925afdb42f13f1d912db87ecda65135eb9fe6352" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:10.271ex; height:2.676ex;" alt="{\displaystyle W\in \mathbb {R} ^{h\times d}}"></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle U\in \mathbb {R} ^{h\times h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>U</mi>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
            <mo>×<!-- × --></mo>
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle U\in \mathbb {R} ^{h\times h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0ff9bb53a5409a1e51f6130b3dfbcdad63324880" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:9.706ex; height:2.676ex;" alt="{\displaystyle U\in \mathbb {R} ^{h\times h}}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle b\in \mathbb {R} ^{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>b</mi>
        <mo>∈<!-- ∈ --></mo>
        <msup>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="double-struck">R</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle b\in \mathbb {R} ^{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/289515b23d7df7e2e09f2ee38951abf345e60080" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.695ex; height:2.676ex;" alt="{\displaystyle b\in \mathbb {R} ^{h}}"></span>: weight matrices and bias vector parameters which need to be learned during training</li></ul>
<p>where the superscripts <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle d}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>d</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle d}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/e85ff03cbe0c7341af6b982e47e9f90d235c66ab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.216ex; height:2.176ex;" alt="d"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle h}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>h</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/b26be3e694314bc90c3215047e4a2010c6ee184a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.339ex; height:2.176ex;" alt="h"></span> refer to the number of input features and number of hidden units, respectively.
</p>
<h4><span class="mw-headline" id="Activation_functions"><a href="https://en.wikipedia.org/wiki/Activation_function" title="Activation function">Activation functions</a></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=6" title="Edit section: Activation functions">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \sigma _{g}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>σ<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>g</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{g}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/086f92de077f853afd7f5d22fb3d305cbf5e0ac3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.349ex; height:2.343ex;" alt="\sigma _{g}"></span>: <a href="https://en.wikipedia.org/wiki/Sigmoid_function" title="Sigmoid function">sigmoid function</a>.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \sigma _{c}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>σ<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{c}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/b436b43abda74fce1a6859e03d34c914c6a240f4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.272ex; height:2.009ex;" alt="\sigma_c"></span>: <a href="https://en.wikipedia.org/wiki/Hyperbolic_tangent" class="mw-redirect" title="Hyperbolic tangent">hyperbolic tangent</a> function.</li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \sigma _{h}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>σ<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{h}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/8a7f19495f5a65d26570b54b7ca332956d27b27b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.506ex; height:2.009ex;" alt="\sigma _{h}"></span>: hyperbolic tangent function or, as the peephole LSTM paper<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Avoid_weasel_words" class="mw-redirect" title="Wikipedia:Avoid weasel words"><span title="The material near this tag possibly uses too vague attribution or weasel words. (November 2017)">which?</span></a></i>]</sup> suggests, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \sigma _{h}(x)=x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>σ<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>h</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma _{h}(x)=x}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/98d34299f4e04f10f7c22e1219bf182712c3e0fc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.074ex; height:2.843ex;" alt="{\displaystyle \sigma _{h}(x)=x}"></span>.<sup id="cite_ref-peepholeLSTM_20-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peepholeLSTM-20">[20]</a></sup><sup id="cite_ref-peephole2002_21-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peephole2002-21">[21]</a></sup></li></ul>
<h3><span class="mw-headline" id="Peephole_LSTM">Peephole LSTM</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=7" title="Edit section: Peephole LSTM">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="thumb tright"><div class="thumbinner" style="width:302px;"><a href="https://en.wikipedia.org/wiki/File:Peephole_Long_Short-Term_Memory.svg" class="image"><img alt="" src="./Long short-term memory - Wikipedia_files/300px-Peephole_Long_Short-Term_Memory.svg.png" width="300" height="165" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/450px-Peephole_Long_Short-Term_Memory.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/53/Peephole_Long_Short-Term_Memory.svg/600px-Peephole_Long_Short-Term_Memory.svg.png 2x" data-file-width="542" data-file-height="298"></a>  <div class="thumbcaption"><div class="magnify"><a href="https://en.wikipedia.org/wiki/File:Peephole_Long_Short-Term_Memory.svg" class="internal" title="Enlarge"></a></div>A <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#Peephole_LSTM">peephole LSTM</a> unit with input (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/add78d8608ad86e54951b8c8bd6c8d8416533d20" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.802ex; height:2.176ex;" alt="i"></span>), output (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle o}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0c1031f61947aa3d1cf3a70ec3e4904df2c3675d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.128ex; height:1.676ex;" alt="o"></span>), and forget (i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"></span>) gates. Each of these gates can be thought as a "standard" neuron in a feed-forward (or multi-layer) neural network: that is, they compute an activation (using an activation function) of a weighted sum. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i_{t},o_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t},o_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/cf0b0dee7b12fd921a114101ff11c83e1606a1f8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.616ex; height:2.509ex;" alt="{\displaystyle i_{t},o_{t}}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/874c306411e808e8191e8aeb95e3440e1c68d6e9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.965ex; height:2.509ex;" alt="f_{t}"></span> represent the activations of respectively the input, output and forget gates, at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"></span>.  The 3 exit arrows from the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"></span> to the 3 gates <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i,o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>,</mo>
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i,o}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/4697b39f565cd54942b9f81d5de46dcdd1174528" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.964ex; height:2.509ex;" alt="{\displaystyle i,o}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"></span> represent the <i>peephole</i> connections. These peephole connections actually denote the contributions of the activation of the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"></span> at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle t-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
        <mo>−<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t-1}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/a215d9553945bb84b3b5a79cc796fb7d6e0629f0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;" alt="t-1"></span>, i.e. the contribution of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>−<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"></span> (and not <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/93578e37f3234419a34df79845836bc0ec5ef76c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.833ex; height:2.009ex;" alt="{\displaystyle c_{t}}"></span>, as the picture may suggest). In other words, the gates <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i,o}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo>,</mo>
        <mi>o</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i,o}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/4697b39f565cd54942b9f81d5de46dcdd1174528" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.964ex; height:2.509ex;" alt="{\displaystyle i,o}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"></span> calculate their activations at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="t"></span> (i.e., respectively, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle i_{t},o_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>i</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>o</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i_{t},o_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/cf0b0dee7b12fd921a114101ff11c83e1606a1f8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.616ex; height:2.509ex;" alt="{\displaystyle i_{t},o_{t}}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle f_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/874c306411e808e8191e8aeb95e3440e1c68d6e9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.965ex; height:2.509ex;" alt="f_{t}"></span>) also considering the activation of the memory cell <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="c"></span> at time step <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle t-1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
        <mo>−<!-- − --></mo>
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t-1}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/a215d9553945bb84b3b5a79cc796fb7d6e0629f0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:4.842ex; height:2.343ex;" alt="t-1"></span>, i.e. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>−<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"></span>.  The single left-to-right arrow exiting the memory cell is <i>not</i> a peephole connection and denotes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/93578e37f3234419a34df79845836bc0ec5ef76c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.833ex; height:2.009ex;" alt="{\displaystyle c_{t}}"></span>.  The little circles containing a <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \times }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>×<!-- × --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \times }</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0ffafff1ad26cbe49045f19a67ce532116a32703" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.019ex; margin-bottom: -0.19ex; width:1.808ex; height:1.509ex;" alt="\times "></span> symbol represent an element-wise multiplication between its inputs. The big circles containing an <i>S</i>-like curve represent the application of a differentiable function (like the sigmoid function) to a weighted sum.  There are many other kinds of LSTMs as well.<sup id="cite_ref-22" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-22">[22]</a></sup></div></div></div>
<p>The figure on the right is a graphical representation of an LSTM unit with peephole connections (i.e. a peephole LSTM).<sup id="cite_ref-peepholeLSTM_20-1" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peepholeLSTM-20">[20]</a></sup><sup id="cite_ref-peephole2002_21-1" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peephole2002-21">[21]</a></sup> Peephole connections allow the gates to access the constant error carousel (CEC), whose activation is the cell state.<sup id="cite_ref-23" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-23">[23]</a></sup> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle h_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>h</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>−<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle h_{t-1}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/cf56fc7e1114417475762546403f3d66460975d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:4.265ex; height:2.509ex;" alt="{\displaystyle h_{t-1}}"></span> is not used, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle c_{t-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>c</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mo>−<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c_{t-1}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/0b5dbc0177993c2ebd927aee23d88bd263770532" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.933ex; height:2.009ex;" alt="{\displaystyle c_{t-1}}"></span> is used instead in most places.
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}c_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}c_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/8a0eddfb6f592041ea04bd26526b52ba1cec192c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -7.338ex; width:44.234ex; height:15.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}x_{t}+U_{f}c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}x_{t}+U_{i}c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}x_{t}+U_{o}c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}x_{t}+U_{c}c_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}"></span></dd></dl>
<h3><span class="mw-headline" id="Peephole_convolutional_LSTM">Peephole convolutional LSTM</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=8" title="Edit section: Peephole convolutional LSTM">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Peephole <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" title="Convolutional neural network">convolutional</a> LSTM.<sup id="cite_ref-24" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-24">[24]</a></sup> The <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle *}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>∗<!-- ∗ --></mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle *}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/8e9972f426d9e07855984f73ee195a21dbc21755" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: 0.079ex; margin-bottom: -0.25ex; width:1.162ex; height:1.509ex;" alt="*"></span> denotes the <a href="https://en.wikipedia.org/wiki/Convolution" title="Convolution">convolution</a> operator.
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>f</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>i</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>g</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>V</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>o</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>i</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>W</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>U</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo>∗<!-- ∗ --></mo>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                    <mo>−<!-- − --></mo>
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>+</mo>
                <msub>
                  <mi>b</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mi>h</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>o</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo>∘<!-- ∘ --></mo>
                <msub>
                  <mi>σ<!-- σ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>h</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>c</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>t</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/ece51269cfa6192bdc05814d7263ee952fc6ce38" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -7.338ex; width:48.955ex; height:15.843ex;" alt="{\displaystyle {\begin{aligned}f_{t}&amp;=\sigma _{g}(W_{f}*x_{t}+U_{f}*h_{t-1}+V_{f}\circ c_{t-1}+b_{f})\\i_{t}&amp;=\sigma _{g}(W_{i}*x_{t}+U_{i}*h_{t-1}+V_{i}\circ c_{t-1}+b_{i})\\o_{t}&amp;=\sigma _{g}(W_{o}*x_{t}+U_{o}*h_{t-1}+V_{o}\circ c_{t-1}+b_{o})\\c_{t}&amp;=f_{t}\circ c_{t-1}+i_{t}\circ \sigma _{c}(W_{c}*x_{t}+U_{c}*h_{t-1}+b_{c})\\h_{t}&amp;=o_{t}\circ \sigma _{h}(c_{t})\end{aligned}}}"></span></dd></dl>
<h2><span class="mw-headline" id="Training">Training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=9" title="Edit section: Training">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>To minimize LSTM's total error on a set of training sequences, iterative <a href="https://en.wikipedia.org/wiki/Gradient_descent" title="Gradient descent">gradient descent</a> such as <a href="https://en.wikipedia.org/wiki/Backpropagation_through_time" title="Backpropagation through time">backpropagation through time</a> can be used to change each weight in proportion to the derivative of the error with respect to it. A problem with using <a href="https://en.wikipedia.org/wiki/Gradient_descent" title="Gradient descent">gradient descent</a> for standard RNNs is that error gradients <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" title="Vanishing gradient problem">vanish</a> exponentially quickly with the size of the time lag between important events. This is due to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle \lim _{n\to \infty }W^{n}=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <munder>
          <mo movablelimits="true" form="prefix">lim</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
            <mo stretchy="false">→<!-- → --></mo>
            <mi mathvariant="normal">∞<!-- ∞ --></mi>
          </mrow>
        </munder>
        <msup>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msup>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lim _{n\to \infty }W^{n}=0}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/4f21d24f36ac54c2e3826fe618891ce17b19e12d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.838ex; width:12.647ex; height:3.843ex;" alt="{\displaystyle \lim _{n\to \infty }W^{n}=0}"></span> if the <a href="https://en.wikipedia.org/wiki/Spectral_radius" title="Spectral radius">spectral radius</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\displaystyle W}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W}</annotation>
  </semantics>
</math></span><img src="./Long short-term memory - Wikipedia_files/54a9c4c547f4d6111f81946cad242b18298d70b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.435ex; height:2.176ex;" alt="W"></span> is smaller than 1.<sup id="cite_ref-25" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-25">[25]</a></sup><sup id="cite_ref-gradf_26-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-gradf-26">[26]</a></sup> With LSTM units, however, when error values are back-propagated from the output, the error remains in the unit's memory. This "error carousel" continuously feeds error back to each of the gates until they learn to cut off the value. Thus, regular backpropagation is effective at training an LSTM unit to remember values for long durations.
</p><p>LSTM can also be trained by a combination of <a href="https://en.wikipedia.org/wiki/Artificial_evolution" class="mw-redirect" title="Artificial evolution">artificial evolution</a> for weights to the hidden units, and <a href="https://en.wikipedia.org/wiki/Pseudo-inverse" class="mw-redirect" title="Pseudo-inverse">pseudo-inverse</a> or <a href="https://en.wikipedia.org/wiki/Support_vector_machine" title="Support vector machine">support vector machines</a> for weights to the output units.<sup id="cite_ref-27" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-27">[27]</a></sup> In <a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> applications LSTM can be trained by <a href="https://en.wikipedia.org/wiki/Reinforcement_learning#Direct_policy_search" title="Reinforcement learning">policy gradient methods</a>, <a href="https://en.wikipedia.org/wiki/Evolution_strategies" class="mw-redirect" title="Evolution strategies">evolution strategies</a> or <a href="https://en.wikipedia.org/wiki/Genetic_algorithms" class="mw-redirect" title="Genetic algorithms">genetic algorithms</a><sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2017)">citation needed</span></a></i>]</sup>.
</p>
<h3><span class="mw-headline" id="CTC_score_function">CTC score function</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=10" title="Edit section: CTC score function">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Many applications use stacks of LSTM RNNs<sup id="cite_ref-fernandez2007_28-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-fernandez2007-28">[28]</a></sup> and train them by <a href="https://en.wikipedia.org/wiki/Connectionist_temporal_classification_(CTC)" class="mw-redirect" title="Connectionist temporal classification (CTC)">connectionist temporal classification (CTC)</a><sup id="cite_ref-graves2006_29-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-graves2006-29">[29]</a></sup> to find an RNN weight matrix that maximizes the probability of the label sequences in a training set, given the corresponding input sequences. CTC achieves both alignment and recognition.
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=11" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Applications of LSTM include:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Robot_control" title="Robot control">Robot control</a><sup id="cite_ref-30" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-30">[30]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Time_series_prediction" class="mw-redirect" title="Time series prediction">Time series prediction</a><sup id="cite_ref-31" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-31">[31]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a><sup id="cite_ref-32" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-32">[32]</a></sup><sup id="cite_ref-33" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-33">[33]</a></sup><sup id="cite_ref-ReferenceA_34-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-ReferenceA-34">[34]</a></sup></li>
<li>Rhythm learning<sup id="cite_ref-peephole2002_21-2" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peephole2002-21">[21]</a></sup></li>
<li>Music composition<sup id="cite_ref-35" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-35">[35]</a></sup></li>
<li>Grammar learning<sup id="cite_ref-36" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-36">[36]</a></sup><sup id="cite_ref-peepholeLSTM_20-2" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-peepholeLSTM-20">[20]</a></sup><sup id="cite_ref-37" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-37">[37]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Handwriting_recognition" title="Handwriting recognition">Handwriting recognition</a><sup id="cite_ref-38" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-38">[38]</a></sup><sup id="cite_ref-39" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-39">[39]</a></sup></li>
<li>Human action recognition<sup id="cite_ref-40" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-40">[40]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Sign_language" title="Sign language">Sign Language Translation</a><sup id="cite_ref-41" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-41">[41]</a></sup></li>
<li>Protein Homology Detection<sup id="cite_ref-42" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-42">[42]</a></sup></li>
<li>Predicting subcellular localization of proteins<sup id="cite_ref-43" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-43">[43]</a></sup></li>
<li>Time series anomaly detection<sup id="cite_ref-44" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-44">[44]</a></sup></li>
<li>Several prediction tasks in the area of business process management<sup id="cite_ref-45" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-45">[45]</a></sup></li>
<li>Prediction in medical care pathways<sup id="cite_ref-46" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-46">[46]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Semantic_parsing" title="Semantic parsing">Semantic parsing</a><sup id="cite_ref-47" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-47">[47]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Object_Co-segmentation" title="Object Co-segmentation">Object Co-segmentation</a><sup id="cite_ref-Wang_Duan_Zhang_Niu_p=1657_48-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-Wang_Duan_Zhang_Niu_p=1657-48">[48]</a></sup><sup id="cite_ref-Duan_Wang_Zhai_Zheng_2018_p._49-0" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-Duan_Wang_Zhai_Zheng_2018_p.-49">[49]</a></sup></li></ul>
<p><br>
LSTM has <a href="https://en.wikipedia.org/wiki/Turing_completeness" title="Turing completeness">Turing completeness</a> in the sense that given enough network units it can compute any result that a conventional computer can compute, provided it has the proper <a href="https://en.wikipedia.org/wiki/Weight" title="Weight">weight</a> <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)" title="Matrix (mathematics)">matrix</a>, which may be viewed as its program<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (October 2017)">citation needed</span></a></i>]</sup><sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag needs further explanation. (October 2017)">further explanation needed</span></a></i>]</sup>.
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Differentiable_neural_computer" title="Differentiable neural computer">Differentiable neural computer</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" title="Gated recurrent unit">Gated recurrent unit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Long-term_potentiation" title="Long-term potentiation">Long-term potentiation</a></li>
<li><a href="https://en.wikipedia.org/wiki/Prefrontal_cortex_basal_ganglia_working_memory" title="Prefrontal cortex basal ganglia working memory">Prefrontal cortex basal ganglia working memory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" title="Recurrent neural network">Recurrent neural network</a></li>
<li><a href="https://en.wikipedia.org/wiki/Time_series" title="Time series">Time series</a></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=13" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="http://www.idsia.ch/~juergen/rnn.html">Recurrent Neural Networks</a> with over 30 LSTM papers by <a href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a>'s group at <a href="https://en.wikipedia.org/wiki/IDSIA" class="mw-redirect" title="IDSIA">IDSIA</a></li>
<li>Gers <a rel="nofollow" class="external text" href="http://www.felixgers.de/papers/phd.pdf">PhD thesis</a> on LSTM networks.</li>
<li><a rel="nofollow" class="external text" href="https://web.archive.org/web/20120522234026/http://etd.uwc.ac.za/usrfiles/modules/etd/docs/etd_init_3937_1174040706.pdf">Fraud detection paper</a> (<a rel="nofollow" class="external text" href="http://etd.uwc.ac.za/bitstream/handle/11394/249/Abidogun_MSC_2005.pdf">original</a>) with two chapters devoted to explaining recurrent neural networks, especially LSTM.</li>
<li><a rel="nofollow" class="external text" href="http://www.cs.umd.edu/~dmonner/papers/nn2012.pdf">Paper</a> on a high-performing extension of LSTM that has been simplified to a single node type and can train arbitrary architectures.</li>
<li><a rel="nofollow" class="external text" href="http://christianherta.de/lehre/dataScience/machineLearning/neuralNetworks/LSTM.html">Tutorial: How to implement LSTM in Python with Theano</a></li>
<li><a rel="nofollow" class="external text" href="http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf">Gers, Felix A., Nicol N. Schraudolph, and Jürgen Schmidhuber. "Learning precise timing with LSTM recurrent networks." Journal of machine learning research 3, no. Aug (2002): 115-143.</a><sup id="cite_ref-50" class="reference"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_note-50">[50]</a></sup></li>
<li><a rel="nofollow" class="external text" href="https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition">Tutorial: How to use LSTMs with TensorFlow in Python on cellphone sensor data</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit&amp;section=14" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-lstm1997-1"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-lstm1997_1-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-lstm1997_1-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal"><a href="https://en.wikipedia.org/wiki/Sepp_Hochreiter" title="Sepp Hochreiter">Sepp Hochreiter</a>; <a href="https://en.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber" title="Jürgen Schmidhuber">Jürgen Schmidhuber</a> (1997). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory">"Long short-term memory"</a>. <i><a href="https://en.wikipedia.org/wiki/Neural_Computation_(journal)" title="Neural Computation (journal)">Neural Computation</a></i>. <b>9</b> (8): 1735–1780. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fneco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a>. <a href="https://en.wikipedia.org/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pubmed/9377276">9377276</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Long+short-term+memory&amp;rft.volume=9&amp;rft.issue=8&amp;rft.pages=1735-1780&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1162%2Fneco.1997.9.8.1735&amp;rft_id=info%3Apmid%2F9377276&amp;rft.au=Sepp+Hochreiter&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F13853244_Long_Short-term_Memory&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r861714446">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output q{quotes:"\"""\"""'""'"}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-limited a,.mw-parser-output .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-lstm2000-2"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-lstm2000_2-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-lstm2000_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Felix A. Gers; Jürgen Schmidhuber; Fred Cummins (2000). <a rel="nofollow" class="external text" href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.5709">"Learning to Forget: Continual Prediction with LSTM"</a>. <i><a href="https://en.wikipedia.org/wiki/Neural_Computation_(journal)" title="Neural Computation (journal)">Neural Computation</a></i>. <b>12</b> (10): 2451–2471. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2F089976600300015015">10.1162/089976600300015015</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Learning+to+Forget%3A+Continual+Prediction+with+LSTM&amp;rft.volume=12&amp;rft.issue=10&amp;rft.pages=2451-2471&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.1162%2F089976600300015015&amp;rft.au=Felix+A.+Gers&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rft.au=Fred+Cummins&amp;rft_id=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.55.5709&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-3" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.mattmahoney.net/dc/text.html#1218">"The Large Text Compression Benchmark"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-01-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Large+Text+Compression+Benchmark&amp;rft_id=http%3A%2F%2Fwww.mattmahoney.net%2Fdc%2Ftext.html%231218&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-4" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, A.; Liwicki, M.; Fernández, S.; Bertolami, R.; Bunke, H.; Schmidhuber, J. (May 2009). <a rel="nofollow" class="external text" href="http://ieeexplore.ieee.org/document/4531750/">"A Novel Connectionist System for Unconstrained Handwriting Recognition"</a>. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>31</b> (5): 855–868. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftpami.2008.137">10.1109/tpami.2008.137</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/0162-8828">0162-8828</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=A+Novel+Connectionist+System+for+Unconstrained+Handwriting+Recognition&amp;rft.volume=31&amp;rft.issue=5&amp;rft.pages=855-868&amp;rft.date=2009-05&amp;rft_id=info%3Adoi%2F10.1109%2Ftpami.2008.137&amp;rft.issn=0162-8828&amp;rft.aulast=Graves&amp;rft.aufirst=A.&amp;rft.au=Liwicki%2C+M.&amp;rft.au=Fern%C3%A1ndez%2C+S.&amp;rft.au=Bertolami%2C+R.&amp;rft.au=Bunke%2C+H.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=http%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F4531750%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-5" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Graves, Alex; Mohamed, Abdel-rahman; Hinton, Geoffrey (2013-03-22). "Speech Recognition with Deep Recurrent Neural Networks". <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1303.5778">1303.5778</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.NE">cs.NE</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Speech+Recognition+with+Deep+Recurrent+Neural+Networks&amp;rft.date=2013-03-22&amp;rft_id=info%3Aarxiv%2F1303.5778&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Mohamed%2C+Abdel-rahman&amp;rft.au=Hinton%2C+Geoffrey&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-6" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.wired.com/2016/06/apple-bringing-ai-revolution-iphone/">"With QuickType, Apple wants to do more than guess your next text. It wants to give you an AI"</a>. <i>WIRED</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-06-16</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=WIRED&amp;rft.atitle=With+QuickType%2C+Apple+wants+to+do+more+than+guess+your+next+text.+It+wants+to+give+you+an+AI.&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F06%2Fapple-bringing-ai-revolution-iphone%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-Beau15-7"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-Beau15_7-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation news">Beaufays, Françoise (August 11, 2015). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html">"The neural networks behind Google Voice transcription"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=The+neural+networks+behind+Google+Voice+transcription&amp;rft.date=2015-08-11&amp;rft.aulast=Beaufays&amp;rft.aufirst=Fran%C3%A7oise&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.at%2F2015%2F08%2Fthe-neural-networks-behind-google-voice.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-GoogleVoiceSearch-8"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-GoogleVoiceSearch_8-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation news">Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 24, 2015). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.uk/2015/09/google-voice-search-faster-and-more.html">"Google voice search: faster and more accurate"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=Google+voice+search%3A+faster+and+more+accurate&amp;rft.date=2015-09-24&amp;rft.aulast=Sak&amp;rft.aufirst=Ha%C5%9Fim&amp;rft.au=Senior%2C+Andrew&amp;rft.au=Rao%2C+Kanishka&amp;rft.au=Beaufays%2C+Fran%C3%A7oise&amp;rft.au=Schalkwyk%2C+Johan&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.uk%2F2015%2F09%2Fgoogle-voice-search-faster-and-more.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-GoogleAllo-9"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-GoogleAllo_9-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation news">Khaitan, Pranav (May 18, 2016). <a rel="nofollow" class="external text" href="http://googleresearch.blogspot.co.at/2016/05/chat-smarter-with-allo.html">"Chat Smarter with Allo"</a>. <i>Research Blog</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+Blog&amp;rft.atitle=Chat+Smarter+with+Allo&amp;rft.date=2016-05-18&amp;rft.aulast=Khaitan&amp;rft.aufirst=Pranav&amp;rft_id=http%3A%2F%2Fgoogleresearch.blogspot.co.at%2F2016%2F05%2Fchat-smarter-with-allo.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-GoogleTranslate-10"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-GoogleTranslate_10-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V.; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin (2016-09-26). "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation". <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1609.08144">1609.08144</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.CL">cs.CL</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Google%27s+Neural+Machine+Translation+System%3A+Bridging+the+Gap+between+Human+and+Machine+Translation&amp;rft.date=2016-09-26&amp;rft_id=info%3Aarxiv%2F1609.08144&amp;rft.aulast=Wu&amp;rft.aufirst=Yonghui&amp;rft.au=Schuster%2C+Mike&amp;rft.au=Chen%2C+Zhifeng&amp;rft.au=Le%2C+Quoc+V.&amp;rft.au=Norouzi%2C+Mohammad&amp;rft.au=Macherey%2C+Wolfgang&amp;rft.au=Krikun%2C+Maxim&amp;rft.au=Cao%2C+Yuan&amp;rft.au=Gao%2C+Qin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-WiredGoogleTranslate-11"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-WiredGoogleTranslate_11-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Metz, Cade (September 27, 2016). <a rel="nofollow" class="external text" href="https://www.wired.com/2016/09/google-claims-ai-breakthrough-machine-translation/">"An Infusion of AI Makes Google Translate More Powerful Than Ever | WIRED"</a>. <i>www.wired.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.wired.com&amp;rft.atitle=An+Infusion+of+AI+Makes+Google+Translate+More+Powerful+Than+Ever+%7C+WIRED&amp;rft.date=2016-09-27&amp;rft.aulast=Metz&amp;rft.aufirst=Cade&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F09%2Fgoogle-claims-ai-breakthrough-machine-translation%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-AppleQuicktype-12"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-AppleQuicktype_12-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Efrati, Amir (June 13, 2016). <a rel="nofollow" class="external text" href="https://www.theinformation.com/apples-machines-can-learn-too">"Apple's Machines Can Learn Too"</a>. <i>The Information</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=Apple%E2%80%99s+Machines+Can+Learn+Too&amp;rft.date=2016-06-13&amp;rft.aulast=Efrati&amp;rft.aufirst=Amir&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Fapples-machines-can-learn-too&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-AppleQuicktype2-13"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-AppleQuicktype2_13-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation news">Ranger, Steve (June 14, 2016). <a rel="nofollow" class="external text" href="http://www.zdnet.com/article/ai-big-data-and-the-iphone-heres-how-apple-plans-to-protect-your-privacy">"iPhone, AI and big data: Here's how Apple plans to protect your privacy | ZDNet"</a>. <i>ZDNet</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ZDNet&amp;rft.atitle=iPhone%2C+AI+and+big+data%3A+Here%27s+how+Apple+plans+to+protect+your+privacy+%7C+ZDNet&amp;rft.date=2016-06-14&amp;rft.aulast=Ranger&amp;rft.aufirst=Steve&amp;rft_id=http%3A%2F%2Fwww.zdnet.com%2Farticle%2Fai-big-data-and-the-iphone-heres-how-apple-plans-to-protect-your-privacy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-AppleSiri-14"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-AppleSiri_14-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Smith, Chris (2016-06-13). <a rel="nofollow" class="external text" href="http://bgr.com/2016/06/13/ios-10-siri-third-party-apps/">"iOS 10: Siri now works in third-party apps, comes with extra AI features"</a>. <i>BGR</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=BGR&amp;rft.atitle=iOS+10%3A+Siri+now+works+in+third-party+apps%2C+comes+with+extra+AI+features&amp;rft.date=2016-06-13&amp;rft.aulast=Smith&amp;rft.aufirst=Chris&amp;rft_id=http%3A%2F%2Fbgr.com%2F2016%2F06%2F13%2Fios-10-siri-third-party-apps%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-AmazonAlexa-15"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-AmazonAlexa_15-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Vogels, Werner (30 November 2016). <a rel="nofollow" class="external text" href="http://www.allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html">"Bringing the Magic of Amazon AI and Alexa to Apps on AWS. - All Things Distributed"</a>. <i>www.allthingsdistributed.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.allthingsdistributed.com&amp;rft.atitle=Bringing+the+Magic+of+Amazon+AI+and+Alexa+to+Apps+on+AWS.+-+All+Things+Distributed&amp;rft.date=2016-11-30&amp;rft.aulast=Vogels&amp;rft.aufirst=Werner&amp;rft_id=http%3A%2F%2Fwww.allthingsdistributed.com%2F2016%2F11%2Famazon-ai-and-alexa-for-all-aws-apps.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-16" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://biometrics.cse.msu.edu/Publications/MachineLearning/Baytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf">"Patient Subtyping via Time-Aware LSTM Networks"</a> <span class="cs1-format">(PDF)</span>. <i>msu.edu</i><span class="reference-accessdate">. Retrieved <span class="nowrap">21 Nov</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=msu.edu&amp;rft.atitle=Patient+Subtyping+via+Time-Aware+LSTM+Networks&amp;rft_id=http%3A%2F%2Fbiometrics.cse.msu.edu%2FPublications%2FMachineLearning%2FBaytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-17" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.kdd.org/kdd2017/papers/view/patient-subtyping-via-time-aware-lstm-networks">"Patient Subtyping via Time-Aware LSTM Networks"</a>. <i>Kdd.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">24 May</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Kdd.org&amp;rft.atitle=Patient+Subtyping+via+Time-Aware+LSTM+Networks&amp;rft_id=http%3A%2F%2Fwww.kdd.org%2Fkdd2017%2Fpapers%2Fview%2Fpatient-subtyping-via-time-aware-lstm-networks&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-18" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.kdd.org/">"SIGKDD"</a>. <i>Kdd.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">24 May</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Kdd.org&amp;rft.atitle=SIGKDD&amp;rft_id=http%3A%2F%2Fwww.kdd.org&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-19" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Haridy, Rich (August 21, 2017). <a rel="nofollow" class="external text" href="http://newatlas.com/microsoft-speech-recognition-equals-humans/50999">"Microsoft's speech recognition system is now as good as a human"</a>. <i>newatlas.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-08-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=newatlas.com&amp;rft.atitle=Microsoft%27s+speech+recognition+system+is+now+as+good+as+a+human&amp;rft.date=2017-08-21&amp;rft.aulast=Haridy&amp;rft.aufirst=Rich&amp;rft_id=http%3A%2F%2Fnewatlas.com%2Fmicrosoft-speech-recognition-equals-humans%2F50999&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-peepholeLSTM-20"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peepholeLSTM_20-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peepholeLSTM_20-1"><sup><i><b>b</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peepholeLSTM_20-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Gers, F. A.; Schmidhuber, J. (2001). <a rel="nofollow" class="external text" href="ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf">"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Neural Networks</i>. <b>12</b> (6): 1333–1340. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.963769">10.1109/72.963769</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=LSTM+Recurrent+Networks+Learn+Simple+Context+Free+and+Context+Sensitive+Languages&amp;rft.volume=12&amp;rft.issue=6&amp;rft.pages=1333-1340&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1109%2F72.963769&amp;rft.aulast=Gers&amp;rft.aufirst=F.+A.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=ftp%3A%2F%2Fftp.idsia.ch%2Fpub%2Fjuergen%2FL-IEEE.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-peephole2002-21"><span class="mw-cite-backlink">^ <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peephole2002_21-0"><span class="cite-accessibility-label">Jump up to: </span><sup><i><b>a</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peephole2002_21-1"><sup><i><b>b</b></i></sup></a> <a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-peephole2002_21-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><cite class="citation journal">Gers, F.; Schraudolph, N.; Schmidhuber, J. (2002). <a rel="nofollow" class="external text" href="http://www.jmlr.org/papers/volume3/gers02a/gers02a.pdf">"Learning precise timing with LSTM recurrent networks"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Machine Learning Research</i>. <b>3</b>: 115–143.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Learning+precise+timing+with+LSTM+recurrent+networks&amp;rft.volume=3&amp;rft.pages=115-143&amp;rft.date=2002&amp;rft.aulast=Gers&amp;rft.aufirst=F.&amp;rft.au=Schraudolph%2C+N.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=http%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume3%2Fgers02a%2Fgers02a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-22" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Klaus Greff; Rupesh Kumar Srivastava; Jan Koutník; Bas R. Steunebrink; Jürgen Schmidhuber (2015). "LSTM: A Search Space Odyssey". <i>IEEE Transactions on Neural Networks and Learning Systems</i>. <b>28</b> (10): 2222. <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1503.04069">1503.04069</a></span>. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FTNNLS.2016.2582924">10.1109/TNNLS.2016.2582924</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks+and+Learning+Systems&amp;rft.atitle=LSTM%3A+A+Search+Space+Odyssey&amp;rft.volume=28&amp;rft.issue=10&amp;rft.pages=2222&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1503.04069&amp;rft_id=info%3Adoi%2F10.1109%2FTNNLS.2016.2582924&amp;rft.au=Klaus+Greff&amp;rft.au=Rupesh+Kumar+Srivastava&amp;rft.au=Jan+Koutn%C3%ADk&amp;rft.au=Bas+R.+Steunebrink&amp;rft.au=J%C3%BCrgen+Schmidhuber&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-23" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gers, F. A.; Schmidhuber, E. (November 2001). <a rel="nofollow" class="external text" href="ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf">"LSTM recurrent networks learn simple context-free and context-sensitive languages"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Neural Networks</i>. <b>12</b> (6): 1333–1340. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F72.963769">10.1109/72.963769</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1045-9227">1045-9227</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks&amp;rft.atitle=LSTM+recurrent+networks+learn+simple+context-free+and+context-sensitive+languages&amp;rft.volume=12&amp;rft.issue=6&amp;rft.pages=1333-1340&amp;rft.date=2001-11&amp;rft_id=info%3Adoi%2F10.1109%2F72.963769&amp;rft.issn=1045-9227&amp;rft.aulast=Gers&amp;rft.aufirst=F.+A.&amp;rft.au=Schmidhuber%2C+E.&amp;rft_id=ftp%3A%2F%2Fftp.idsia.ch%2Fpub%2Fjuergen%2FL-IEEE.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-24" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Xingjian Shi; Zhourong Chen; Hao Wang; Dit-Yan Yeung; Wai-kin Wong; Wang-chun Woo (2015). "Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting". <i>Proceedings of the 28th International Conference on Neural Information Processing Systems</i>: 802–810. <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1506.04214">1506.04214</a></span>. <a href="https://en.wikipedia.org/wiki/Bibcode" title="Bibcode">Bibcode</a>:<a rel="nofollow" class="external text" href="http://adsabs.harvard.edu/abs/2015arXiv150604214S">2015arXiv150604214S</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+28th+International+Conference+on+Neural+Information+Processing+Systems&amp;rft.atitle=Convolutional+LSTM+Network%3A+A+Machine+Learning+Approach+for+Precipitation+Nowcasting&amp;rft.pages=802-810&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1506.04214&amp;rft_id=info%3Abibcode%2F2015arXiv150604214S&amp;rft.au=Xingjian+Shi&amp;rft.au=Zhourong+Chen&amp;rft.au=Hao+Wang&amp;rft.au=Dit-Yan+Yeung&amp;rft.au=Wai-kin+Wong&amp;rft.au=Wang-chun+Woo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-25" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">S. Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f. Informatik, Technische Univ. Munich, 1991.</span>
</li>
<li id="cite_note-gradf-26"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-gradf_26-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation book">Hochreiter, S.; Bengio, Y.; Frasconi, P.; Schmidhuber, J. (2001). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/2839938_Gradient_Flow_in_Recurrent_Nets_the_Difficulty_of_Learning_Long-Term_Dependencies">"Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies (PDF Download Available)"</a>.  In Kremer and, S. C.; Kolen, J. F. <i>A Field Guide to Dynamical Recurrent Neural Networks</i>. <i>ResearchGate</i>. IEEE Press<span class="reference-accessdate">. Retrieved <span class="nowrap">2017-06-27</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Gradient+Flow+in+Recurrent+Nets%3A+the+Difficulty+of+Learning+Long-Term+Dependencies+%28PDF+Download+Available%29&amp;rft.btitle=A+Field+Guide+to+Dynamical+Recurrent+Neural+Networks.&amp;rft.pub=IEEE+Press&amp;rft.date=2001&amp;rft.aulast=Hochreiter&amp;rft.aufirst=S.&amp;rft.au=Bengio%2C+Y.&amp;rft.au=Frasconi%2C+P.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F2839938_Gradient_Flow_in_Recurrent_Nets_the_Difficulty_of_Learning_Long-Term_Dependencies&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-27" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Schmidhuber, J.; Wierstra, D.; Gagliolo, M.; Gomez, F. (2007). "Training Recurrent Networks by Evolino". <i>Neural Computation</i>. <b>19</b> (3): 757–779. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fneco.2007.19.3.757">10.1162/neco.2007.19.3.757</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Training+Recurrent+Networks+by+Evolino&amp;rft.volume=19&amp;rft.issue=3&amp;rft.pages=757-779&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1162%2Fneco.2007.19.3.757&amp;rft.aulast=Schmidhuber&amp;rft.aufirst=J.&amp;rft.au=Wierstra%2C+D.&amp;rft.au=Gagliolo%2C+M.&amp;rft.au=Gomez%2C+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-fernandez2007-28"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-fernandez2007_28-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Fernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007). "Sequence labelling in structured domains with hierarchical recurrent neural networks". <i>Proc. 20th Int. Joint Conf. on Artificial In℡ligence, Ijcai 2007</i>: 774–779. <a href="https://en.wikipedia.org/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.79.1887">10.1.1.79.1887</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc.+20th+Int.+Joint+Conf.+on+Artificial+In%E2%84%A1ligence%2C+Ijcai+2007&amp;rft.atitle=Sequence+labelling+in+structured+domains+with+hierarchical+recurrent+neural+networks&amp;rft.pages=774-779&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.79.1887&amp;rft.aulast=Fern%C3%A1ndez&amp;rft.aufirst=Santiago&amp;rft.au=Graves%2C+Alex&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-graves2006-29"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-graves2006_29-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, Alex; Fernández, Santiago; Gomez, Faustino (2006). "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks". <i>In Proceedings of the International Conference on Machine Learning, ICML 2006</i>: 369–376. <a href="https://en.wikipedia.org/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&nbsp;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.75.6306">10.1.1.75.6306</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=In+Proceedings+of+the+International+Conference+on+Machine+Learning%2C+ICML+2006&amp;rft.atitle=Connectionist+temporal+classification%3A+Labelling+unsegmented+sequence+data+with+recurrent+neural+networks&amp;rft.pages=369-376&amp;rft.date=2006&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.75.6306&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Fern%C3%A1ndez%2C+Santiago&amp;rft.au=Gomez%2C+Faustino&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-30" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Mayer, H.; Gomez, F.; Wierstra, D.; Nagy, I.; Knoll, A.; Schmidhuber, J. (October 2006). <a rel="nofollow" class="external text" href="http://ieeexplore.ieee.org/document/4059310/">"A System for Robotic Heart Surgery that Learns to Tie Knots Using Recurrent Neural Networks"</a>. <i>2006 IEEE/RSJ International Conference on Intelligent Robots and Systems</i>: 543–548. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FIROS.2006.282190">10.1109/IROS.2006.282190</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-4244-0258-1" title="Special:BookSources/1-4244-0258-1">1-4244-0258-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=2006+IEEE%2FRSJ+International+Conference+on+Intelligent+Robots+and+Systems&amp;rft.atitle=A+System+for+Robotic+Heart+Surgery+that+Learns+to+Tie+Knots+Using+Recurrent+Neural+Networks&amp;rft.pages=543-548&amp;rft.date=2006-10&amp;rft_id=info%3Adoi%2F10.1109%2FIROS.2006.282190&amp;rft.isbn=1-4244-0258-1&amp;rft.aulast=Mayer&amp;rft.aufirst=H.&amp;rft.au=Gomez%2C+F.&amp;rft.au=Wierstra%2C+D.&amp;rft.au=Nagy%2C+I.&amp;rft.au=Knoll%2C+A.&amp;rft.au=Schmidhuber%2C+J.&amp;rft_id=http%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F4059310%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-31" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wierstra, Daan; Schmidhuber, J.; Gomez, F. J. (2005). <a rel="nofollow" class="external text" href="https://www.academia.edu/5830256/Evolino_Hybrid_Neuroevolution_Optimal_Linear_Search_for_Sequence_Learning">"Evolino: Hybrid Neuroevolution/Optimal Linear Search for Sequence Learning"</a>. <i>Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI), Edinburgh</i>: 853–858.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+19th+International+Joint+Conference+on+Artificial+Intelligence+%28IJCAI%29%2C+Edinburgh&amp;rft.atitle=Evolino%3A+Hybrid+Neuroevolution%2FOptimal+Linear+Search+for+Sequence+Learning&amp;rft.pages=853-858&amp;rft.date=2005&amp;rft.aulast=Wierstra&amp;rft.aufirst=Daan&amp;rft.au=Schmidhuber%2C+J.&amp;rft.au=Gomez%2C+F.+J.&amp;rft_id=https%3A%2F%2Fwww.academia.edu%2F5830256%2FEvolino_Hybrid_Neuroevolution_Optimal_Linear_Search_for_Sequence_Learning&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-32" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, A.; Schmidhuber, J. (2005). "Framewise phoneme classification with bidirectional LSTM and other neural network architectures". <i>Neural Networks</i>. <b>18</b> (5–6): 602–610. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.neunet.2005.06.042">10.1016/j.neunet.2005.06.042</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Framewise+phoneme+classification+with+bidirectional+LSTM+and+other+neural+network+architectures&amp;rft.volume=18&amp;rft.issue=5%E2%80%936&amp;rft.pages=602-610&amp;rft.date=2005&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neunet.2005.06.042&amp;rft.aulast=Graves&amp;rft.aufirst=A.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-33" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Fernández, Santiago; Graves, Alex; Schmidhuber, Jürgen (2007). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=1778066.1778092">"An Application of Recurrent Neural Networks to Discriminative Keyword Spotting"</a>. <i>Proceedings of the 17th International Conference on Artificial Neural Networks</i>. ICANN'07. Berlin, Heidelberg: Springer-Verlag: 220–229. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/3540746935" title="Special:BookSources/3540746935">3540746935</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+17th+International+Conference+on+Artificial+Neural+Networks&amp;rft.atitle=An+Application+of+Recurrent+Neural+Networks+to+Discriminative+Keyword+Spotting&amp;rft.pages=220-229&amp;rft.date=2007&amp;rft.isbn=3540746935&amp;rft.aulast=Fern%C3%A1ndez&amp;rft.aufirst=Santiago&amp;rft.au=Graves%2C+Alex&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D1778066.1778092&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-ReferenceA-34"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-ReferenceA_34-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, Alex; Mohamed, Abdel-rahman; Hinton, Geoffrey (2013). "Speech Recognition with Deep Recurrent Neural Networks". <i>Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</i>: 6645–6649.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Acoustics%2C+Speech+and+Signal+Processing+%28ICASSP%29%2C+2013+IEEE+International+Conference+on&amp;rft.atitle=Speech+Recognition+with+Deep+Recurrent+Neural+Networks&amp;rft.pages=6645-6649&amp;rft.date=2013&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Mohamed%2C+Abdel-rahman&amp;rft.au=Hinton%2C+Geoffrey&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-35" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Eck, Douglas; Schmidhuber, Jürgen (2002-08-28). <a rel="nofollow" class="external text" href="https://link.springer.com/chapter/10.1007/3-540-46084-5_47">"Learning the Long-Term Structure of the Blues"</a>. <i>Artificial Neural Networks — ICANN 2002</i>. Lecture Notes in Computer Science. Springer, Berlin, Heidelberg. <b>2415</b>: 284–289. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F3-540-46084-5_47">10.1007/3-540-46084-5_47</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/3540460845" title="Special:BookSources/3540460845">3540460845</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Neural+Networks+%E2%80%94+ICANN+2002&amp;rft.atitle=Learning+the+Long-Term+Structure+of+the+Blues&amp;rft.volume=2415&amp;rft.pages=284-289&amp;rft.date=2002-08-28&amp;rft_id=info%3Adoi%2F10.1007%2F3-540-46084-5_47&amp;rft.isbn=3540460845&amp;rft.aulast=Eck&amp;rft.aufirst=Douglas&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F3-540-46084-5_47&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-36" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Schmidhuber, J.; Gers, F.; Eck, D.; Schmidhuber, J.; Gers, F. (2002). "Learning nonregular languages: A comparison of simple recurrent networks and LSTM". <i>Neural Computation</i>. <b>14</b> (9): 2039–2041. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2F089976602320263980">10.1162/089976602320263980</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Learning+nonregular+languages%3A+A+comparison+of+simple+recurrent+networks+and+LSTM&amp;rft.volume=14&amp;rft.issue=9&amp;rft.pages=2039-2041&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1162%2F089976602320263980&amp;rft.aulast=Schmidhuber&amp;rft.aufirst=J.&amp;rft.au=Gers%2C+F.&amp;rft.au=Eck%2C+D.&amp;rft.au=Schmidhuber%2C+J.&amp;rft.au=Gers%2C+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-37" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Perez-Ortiz, J. A.; Gers, F. A.; Eck, D.; Schmidhuber, J. (2003). "Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets". <i>Neural Networks</i>. <b>16</b> (2): 241–250. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fs0893-6080%2802%2900219-8">10.1016/s0893-6080(02)00219-8</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Networks&amp;rft.atitle=Kalman+filters+improve+LSTM+network+performance+in+problems+unsolvable+by+traditional+recurrent+nets&amp;rft.volume=16&amp;rft.issue=2&amp;rft.pages=241-250&amp;rft.date=2003&amp;rft_id=info%3Adoi%2F10.1016%2Fs0893-6080%2802%2900219-8&amp;rft.aulast=Perez-Ortiz&amp;rft.aufirst=J.+A.&amp;rft.au=Gers%2C+F.+A.&amp;rft.au=Eck%2C+D.&amp;rft.au=Schmidhuber%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-38" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">A. Graves, J. Schmidhuber. Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks. Advances in Neural Information Processing Systems 22, NIPS'22, pp 545–552, Vancouver, MIT Press, 2009.</span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-39" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Graves, Alex; Fernández, Santiago; Liwicki, Marcus; Bunke, Horst; Schmidhuber, Jürgen (2007). <a rel="nofollow" class="external text" href="http://dl.acm.org/citation.cfm?id=2981562.2981635">"Unconstrained Online Handwriting Recognition with Recurrent Neural Networks"</a>. <i>Proceedings of the 20th International Conference on Neural Information Processing Systems</i>. NIPS'07. USA: Curran Associates Inc.: 577–584. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9781605603520" title="Special:BookSources/9781605603520">9781605603520</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+20th+International+Conference+on+Neural+Information+Processing+Systems&amp;rft.atitle=Unconstrained+Online+Handwriting+Recognition+with+Recurrent+Neural+Networks&amp;rft.pages=577-584&amp;rft.date=2007&amp;rft.isbn=9781605603520&amp;rft.aulast=Graves&amp;rft.aufirst=Alex&amp;rft.au=Fern%C3%A1ndez%2C+Santiago&amp;rft.au=Liwicki%2C+Marcus&amp;rft.au=Bunke%2C+Horst&amp;rft.au=Schmidhuber%2C+J%C3%BCrgen&amp;rft_id=http%3A%2F%2Fdl.acm.org%2Fcitation.cfm%3Fid%3D2981562.2981635&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-40" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">M. Baccouche, F. Mamalet, C Wolf, C. Garcia, A. Baskurt. Sequential Deep Learning for Human Action Recognition. 2nd International Workshop on Human Behavior Understanding (HBU), A.A. Salah, B. Lepri ed. Amsterdam, Netherlands. pp. 29–39. Lecture Notes in Computer Science 7065. Springer. 2011</span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-41" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation web">Huang, Jie; Zhou, Wengang; Zhang, Qilin; Li, Houqiang; Li, Weiping (2018-01-30). <a rel="nofollow" class="external text" href="https://arxiv.org/pdf/1801.10111.pdf">"Video-based Sign Language Recognition without Temporal Segmentation"</a> <span class="cs1-format">(PDF)</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Video-based+Sign+Language+Recognition+without+Temporal+Segmentation&amp;rft.date=2018-01-30&amp;rft.aulast=Huang&amp;rft.aufirst=Jie&amp;rft.au=Zhou%2C+Wengang&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Li%2C+Houqiang&amp;rft.au=Li%2C+Weiping&amp;rft_id=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.10111.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-42" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Hochreiter, S.; Heusel, M.; Obermayer, K. (2007). "Fast model-based protein homology detection without alignment". <i>Bioinformatics</i>. <b>23</b> (14): 1728–1736. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtm247">10.1093/bioinformatics/btm247</a>. <a href="https://en.wikipedia.org/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.ncbi.nlm.nih.gov/pubmed/17488755">17488755</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bioinformatics&amp;rft.atitle=Fast+model-based+protein+homology+detection+without+alignment&amp;rft.volume=23&amp;rft.issue=14&amp;rft.pages=1728-1736&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1093%2Fbioinformatics%2Fbtm247&amp;rft_id=info%3Apmid%2F17488755&amp;rft.aulast=Hochreiter&amp;rft.aufirst=S.&amp;rft.au=Heusel%2C+M.&amp;rft.au=Obermayer%2C+K.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-43" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Thireou, T.; Reczko, M. (2007). "Bidirectional Long Short-Term Memory Networks for predicting the subcellular localization of eukaryotic proteins". <i>IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</i>. <b>4</b> (3): 441–446. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftcbb.2007.1015">10.1109/tcbb.2007.1015</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE%2FACM+Transactions+on+Computational+Biology+and+Bioinformatics+%28TCBB%29&amp;rft.atitle=Bidirectional+Long+Short-Term+Memory+Networks+for+predicting+the+subcellular+localization+of+eukaryotic+proteins&amp;rft.volume=4&amp;rft.issue=3&amp;rft.pages=441-446&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1109%2Ftcbb.2007.1015&amp;rft.aulast=Thireou&amp;rft.aufirst=T.&amp;rft.au=Reczko%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-44" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Malhotra, Pankaj; Vig, Lovekesh; Shroff, Gautam; Agarwal, Puneet (April 2015). <a rel="nofollow" class="external text" href="https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf">"Long Short Term Memory Networks for Anomaly Detection in Time Series"</a> <span class="cs1-format">(PDF)</span>. <i>European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning — ESANN 2015</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=European+Symposium+on+Artificial+Neural+Networks%2C+Computational+Intelligence+and+Machine+Learning+%E2%80%94+ESANN+2015&amp;rft.atitle=Long+Short+Term+Memory+Networks+for+Anomaly+Detection+in+Time+Series&amp;rft.date=2015-04&amp;rft.aulast=Malhotra&amp;rft.aufirst=Pankaj&amp;rft.au=Vig%2C+Lovekesh&amp;rft.au=Shroff%2C+Gautam&amp;rft.au=Agarwal%2C+Puneet&amp;rft_id=https%3A%2F%2Fwww.elen.ucl.ac.be%2FProceedings%2Fesann%2Fesannpdf%2Fes2015-56.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-45" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Tax, N.; Verenich, I.; La Rosa, M.; Dumas, M. (2017). <a rel="nofollow" class="external text" href="https://link.springer.com/chapter/10.1007/978-3-319-59536-8_30">"Predictive Business Process Monitoring with LSTM neural networks"</a>. <i>Proceedings of the International Conference on Advanced Information Systems Engineering (CAiSE)</i>: 477–492. <a href="https://en.wikipedia.org/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1612.02130">1612.02130</a></span>. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-59536-8_30">10.1007/978-3-319-59536-8_30</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+International+Conference+on+Advanced+Information+Systems+Engineering+%28CAiSE%29&amp;rft.atitle=Predictive+Business+Process+Monitoring+with+LSTM+neural+networks&amp;rft.pages=477-492&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1612.02130&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-59536-8_30&amp;rft.aulast=Tax&amp;rft.aufirst=N.&amp;rft.au=Verenich%2C+I.&amp;rft.au=La+Rosa%2C+M.&amp;rft.au=Dumas%2C+M.&amp;rft_id=https%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-59536-8_30&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-46" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Choi, E.; Bahadori, M.T.; Schuetz, E.; Stewart, W.; Sun, J. (2016). <a rel="nofollow" class="external text" href="http://proceedings.mlr.press/v56/Choi16.html">"Doctor AI: Predicting Clinical Events via Recurrent Neural Networks"</a>. <i>Proceedings of the 1st Machine Learning for Healthcare Conference</i>: 301–318.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+1st+Machine+Learning+for+Healthcare+Conference&amp;rft.atitle=Doctor+AI%3A+Predicting+Clinical+Events+via+Recurrent+Neural+Networks&amp;rft.pages=301-318&amp;rft.date=2016&amp;rft.aulast=Choi&amp;rft.aufirst=E.&amp;rft.au=Bahadori%2C+M.T.&amp;rft.au=Schuetz%2C+E.&amp;rft.au=Stewart%2C+W.&amp;rft.au=Sun%2C+J.&amp;rft_id=http%3A%2F%2Fproceedings.mlr.press%2Fv56%2FChoi16.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-47" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">Jia, Robin; Liang, Percy (2016-06-11). <a href="https://arxiv.org/abs/1606.03622" class="extiw" title="arxiv:1606.03622">"Data Recombination for Neural Semantic Parsing"</a>. <i>arXiv:1606.03622 [cs]</i>.</span>
</li>
<li id="cite_note-Wang_Duan_Zhang_Niu_p=1657-48"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-Wang_Duan_Zhang_Niu_p=1657_48-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation journal">Wang, Le; Duan, Xuhuan; Zhang, Qilin; Niu, Zhenxing; Hua, Gang; Zheng, Nanning (2018-05-22). <a rel="nofollow" class="external text" href="https://qilin-zhang.github.io/_pages/pdfs/Segment-Tube_Spatio-Temporal_Action_Localization_in_Untrimmed_Videos_with_Per-Frame_Segmentation.pdf">"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation"</a> <span class="cs1-format">(PDF)</span>. <i>Sensors</i>. MDPI AG. <b>18</b> (5): 1657. <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.3390%2Fs18051657">10.3390/s18051657</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&nbsp;<a rel="nofollow" class="external text" href="https://www.worldcat.org/issn/1424-8220">1424-8220</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sensors&amp;rft.atitle=Segment-Tube%3A+Spatio-Temporal+Action+Localization+in+Untrimmed+Videos+with+Per-Frame+Segmentation&amp;rft.volume=18&amp;rft.issue=5&amp;rft.pages=1657&amp;rft.date=2018-05-22&amp;rft_id=info%3Adoi%2F10.3390%2Fs18051657&amp;rft.issn=1424-8220&amp;rft.aulast=Wang&amp;rft.aufirst=Le&amp;rft.au=Duan%2C+Xuhuan&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Niu%2C+Zhenxing&amp;rft.au=Hua%2C+Gang&amp;rft.au=Zheng%2C+Nanning&amp;rft_id=https%3A%2F%2Fqilin-zhang.github.io%2F_pages%2Fpdfs%2FSegment-Tube_Spatio-Temporal_Action_Localization_in_Untrimmed_Videos_with_Per-Frame_Segmentation.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-Duan_Wang_Zhai_Zheng_2018_p.-49"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-Duan_Wang_Zhai_Zheng_2018_p._49-0" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text"><cite class="citation conference">Duan, Xuhuan; Wang, Le; Zhai, Changbo; Zheng, Nanning; Zhang, Qilin; Niu, Zhenxing; Hua, Gang (2018). <i>Joint Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation</i>. 25th IEEE International Conference on Image Processing (ICIP). <a href="https://en.wikipedia.org/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ficip.2018.8451692">10.1109/icip.2018.8451692</a>. <a href="https://en.wikipedia.org/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-4799-7061-2" title="Special:BookSources/978-1-4799-7061-2">978-1-4799-7061-2</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Joint+Spatio-Temporal+Action+Localization+in+Untrimmed+Videos+with+Per-Frame+Segmentation&amp;rft.pub=25th+IEEE+International+Conference+on+Image+Processing+%28ICIP%29&amp;rft.date=2018&amp;rft_id=info%3Adoi%2F10.1109%2Ficip.2018.8451692&amp;rft.isbn=978-1-4799-7061-2&amp;rft.aulast=Duan&amp;rft.aufirst=Xuhuan&amp;rft.au=Wang%2C+Le&amp;rft.au=Zhai%2C+Changbo&amp;rft.au=Zheng%2C+Nanning&amp;rft.au=Zhang%2C+Qilin&amp;rft.au=Niu%2C+Zhenxing&amp;rft.au=Hua%2C+Gang&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALong+short-term+memory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r861714446"></span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#cite_ref-50" aria-label="Jump up" title="Jump up">^</a></b></span> <span class="reference-text">[Gers, Felix A., Nicol N. Schraudolph, and Jürgen Schmidhuber. "Learning precise timing with LSTM recurrent networks." Journal of machine learning research 3, no. Aug (2002): 115-143.]</span>
</li>
</ol></div></div>

<!-- 
NewPP limit report
Parsed by mw1268
Cached time: 20181206082507
Cache expiry: 1900800
Dynamic content: false
CPU time usage: 0.732 seconds
Real time usage: 0.904 seconds
Preprocessor visited node count: 3453/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 124592/2097152 bytes
Template argument size: 3463/2097152 bytes
Highest expansion depth: 11/40
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 134625/5000000 bytes
Number of Wikibase entities loaded: 5/400
Lua time usage: 0.379/10.000 seconds
Lua memory usage: 5.75 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  640.383      1 -total
 70.28%  450.080      1 Template:Reflist
 42.86%  274.440     26 Template:Cite_journal
 11.67%   74.744      5 Template:Fix
 11.01%   70.492      3 Template:Citation_needed
 10.28%   65.838      1 Template:Machine_learning_bar
  9.68%   61.983      1 Template:Sidebar_with_collapsible_lists
  7.65%   48.979     11 Template:Cite_web
  6.68%   42.760      8 Template:Category_handler
  4.19%   26.834      5 Template:Delink
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:10711453-0!canonical!math=5 and timestamp 20181206082506 and revision id 870076484
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;oldid=870076484">https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;oldid=870076484</a>"					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="https://en.wikipedia.org/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="https://en.wikipedia.org/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_unsourced_statements_from_October_2017" title="Category:Articles with unsourced statements from October 2017">Articles with unsourced statements from October 2017</a></li><li><a href="https://en.wikipedia.org/wiki/Category:All_articles_with_specifically_marked_weasel-worded_phrases" title="Category:All articles with specifically marked weasel-worded phrases">All articles with specifically marked weasel-worded phrases</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Articles_with_specifically_marked_weasel-worded_phrases_from_November_2017" title="Category:Articles with specifically marked weasel-worded phrases from November 2017">Articles with specifically marked weasel-worded phrases from November 2017</a></li><li><a href="https://en.wikipedia.org/wiki/Category:Wikipedia_articles_needing_clarification_from_October_2017" title="Category:Wikipedia articles needing clarification from October 2017">Wikipedia articles needing clarification from October 2017</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="https://en.wikipedia.org/wiki/Special:MyTalk" title="Discussion about edits from this IP address [alt-shift-n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="https://en.wikipedia.org/wiki/Special:MyContributions" title="A list of edits made from this IP address [alt-shift-y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&amp;returnto=Long+short-term+memory" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="https://en.wikipedia.org/w/index.php?title=Special:UserLogin&amp;returnto=Long+short-term+memory" title="You&#39;re encouraged to log in; however, it&#39;s not mandatory. [alt-shift-o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="https://en.wikipedia.org/wiki/Long_short-term_memory" title="View the content page [alt-shift-c]" accesskey="c">Article</a></span></li><li id="ca-talk"><span><a href="https://en.wikipedia.org/wiki/Talk:Long_short-term_memory" rel="discussion" title="Discussion about the content page [alt-shift-t]" accesskey="t">Talk</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label">
						<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Read</a></span></li><li id="ca-edit" class="collapsible"><span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=edit" title="Edit this page [alt-shift-e]" accesskey="e">Edit</a></span></li><li id="ca-history" class="collapsible"><span><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=history" title="Past revisions of this page [alt-shift-h]" accesskey="h">View history</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label" style="">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label">
						<h3 id="p-cactions-label"><span>More</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>
						<form action="https://en.wikipedia.org/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [alt-shift-f]" accesskey="f" id="searchInput" tabindex="1" autocomplete="off"><input type="hidden" value="Special:Search" name="title"><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton">							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="https://en.wikipedia.org/wiki/Main_Page" title="Visit the main page [alt-shift-z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="https://en.wikipedia.org/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="https://en.wikipedia.org/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="https://en.wikipedia.org/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="https://en.wikipedia.org/wiki/Special:Random" title="Load a random article [alt-shift-x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="https://shop.wikimedia.org/" title="Visit the Wikipedia store">Wikipedia store</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">
			<h3 id="p-interaction-label">Interaction</h3>
			<div class="body">
								<ul>
					<li id="n-help"><a href="https://en.wikipedia.org/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="https://en.wikipedia.org/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="https://en.wikipedia.org/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [alt-shift-r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="https://en.wikipedia.org/wiki/Special:WhatLinksHere/Long_short-term_memory" title="List of all English Wikipedia pages containing links to this page [alt-shift-j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Long_short-term_memory" rel="nofollow" title="Recent changes in pages linked from this page [alt-shift-k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [alt-shift-u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="https://en.wikipedia.org/wiki/Special:SpecialPages" title="A list of all special pages [alt-shift-q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;oldid=870076484" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q6673524" title="Link to connected data repository item [alt-shift-g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="https://en.wikipedia.org/w/index.php?title=Special:CiteThisPage&amp;page=Long_short-term_memory&amp;id=870076484" title="Information on how to cite this page">Cite this page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Print/export</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="https://en.wikipedia.org/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Long+short-term+memory">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="https://en.wikipedia.org/w/index.php?title=Special:ElectronPdf&amp;page=Long+short-term+memory&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;printable=yes" title="Printable version of this page [alt-shift-p]" accesskey="p">Printable version</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label"><button class="uls-settings-trigger" title="Language settings"></button>
			<h3 id="p-lang-label">Languages</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Long_short-term_memory" title="Long short-term memory – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%AD%D8%A7%D9%81%D8%B8%D9%87_%D8%B7%D9%88%D9%84%D8%A7%D9%86%DB%8C_%DA%A9%D9%88%D8%AA%D8%A7%D9%87-%D9%85%D8%AF%D8%AA" title="حافظه طولانی کوتاه-مدت – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D0%BB%D0%B3%D0%B0%D1%8F_%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%BE%D1%81%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C" title="Долгая краткосрочная память – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%94%D0%BE%D0%B2%D0%B3%D0%B0_%D0%BA%D0%BE%D1%80%D0%BE%D1%82%D0%BA%D0%BE%D1%87%D0%B0%D1%81%D0%BD%D0%B0_%D0%BF%D0%B0%D0%BC%27%D1%8F%D1%82%D1%8C" title="Довга короткочасна пам&#39;ять – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6" title="長短期記憶 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li>				</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q6673524#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> This page was last edited on 22 November 2018, at 06:07<span class="anonymous-show">&nbsp;(UTC)</span>.</li>
								<li id="footer-info-copyright">Text is available under the <a rel="license" href="https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="https://creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="https://foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="https://foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="https://www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="https://en.wikipedia.org/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
								<li id="footer-places-contact"><a href="https://en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
								<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
								<li id="footer-places-mobileview"><a href="https://en.m.wikipedia.org/w/index.php?title=Long_short-term_memory&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
							<li style="display: none;"><a href="https://en.wikipedia.org/wiki/Long_short-term_memory#">Enable previews</a></li></ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="./Long short-term memory - Wikipedia_files/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"></a>					</li>
										<li id="footer-poweredbyico">
						<a href="https://www.mediawiki.org/"><img src="./Long short-term memory - Wikipedia_files/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.732","walltime":"0.904","ppvisitednodes":{"value":3453,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":124592,"limit":2097152},"templateargumentsize":{"value":3463,"limit":2097152},"expansiondepth":{"value":11,"limit":40},"expensivefunctioncount":{"value":8,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":134625,"limit":5000000},"entityaccesscount":{"value":5,"limit":400},"timingprofile":["100.00%  640.383      1 -total"," 70.28%  450.080      1 Template:Reflist"," 42.86%  274.440     26 Template:Cite_journal"," 11.67%   74.744      5 Template:Fix"," 11.01%   70.492      3 Template:Citation_needed"," 10.28%   65.838      1 Template:Machine_learning_bar","  9.68%   61.983      1 Template:Sidebar_with_collapsible_lists","  7.65%   48.979     11 Template:Cite_web","  6.68%   42.760      8 Template:Category_handler","  4.19%   26.834      5 Template:Delink"]},"scribunto":{"limitreport-timeusage":{"value":"0.379","limit":"10.000"},"limitreport-memusage":{"value":6034550,"limit":52428800}},"cachereport":{"origin":"mw1268","timestamp":"20181206082507","ttl":1900800,"transientcontent":false}}});mw.config.set({"wgBackendResponseTime":100,"wgHostname":"mw1275"});});</script>
	

<script type="text/javascript">( function(){ window.SIG_EXT = {}; } )()</script><div id="mwe-popups-svg"><svg xmlns="http://www.w3.org/2000/svg" width="0" height="0"><defs><clippath id="mwe-popups-mask"><polygon points="0 8, 10 8, 18 0, 26 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-mask-flip"><polygon points="0 8, 274 8, 282 0, 290 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-landscape-mask"><polygon points="0 8, 174 8, 182 0, 190 8, 1000 8, 1000 1000, 0 1000"></polygon></clippath><clippath id="mwe-popups-landscape-mask-flip"><polygon points="0 0, 1000 0, 1000 242, 190 242, 182 250, 174 242, 0 242"></polygon></clippath></defs></svg></div><div class="suggestions" style="display: none; font-size: 13px;"><div class="suggestions-results"></div><div class="suggestions-special"></div></div><a accesskey="v" href="https://en.wikipedia.org/wiki/Long_short-term_memory?action=edit" class="oo-ui-element-hidden"></a></body></html>